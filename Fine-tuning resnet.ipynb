{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0650ccb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ivbeveren/.local/lib/python3.11/site-packages/pydub/utils.py:170: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\n",
      "  warn(\"Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\", RuntimeWarning)\n",
      "torchvision is not available - cannot save figures\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# from speechbrain.inference.speaker import SpeakerRecognition\n",
    "import os\n",
    "from pydub import AudioSegment\n",
    "import speechbrain\n",
    "import torch\n",
    "import torchaudio\n",
    "import random\n",
    "\n",
    "from speechbrain.augment.time_domain import Resample\n",
    "from speechbrain.dataio.dataio import read_audio\n",
    "import torchaudio.transforms as T\n",
    "from speechbrain.lobes.features import Fbank\n",
    "from speechbrain.processing.features import InputNormalization\n",
    "from pytorch_metric_learning import losses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "7dad6130-7202-4346-ad22-a8a6b8f5a322",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting pytorch-metric-learning\n",
      "  Downloading pytorch_metric_learning-2.5.0-py3-none-any.whl (119 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.1/119.1 kB\u001b[0m \u001b[31m24.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy in /sw/arch/RHEL8/EB_production/2023/software/SciPy-bundle/2023.07-gfbf-2023a/lib/python3.11/site-packages (from pytorch-metric-learning) (1.25.1)\n",
      "Requirement already satisfied: scikit-learn in /home/ivbeveren/.local/lib/python3.11/site-packages (from pytorch-metric-learning) (1.4.2)\n",
      "Requirement already satisfied: torch>=1.6.0 in /home/ivbeveren/.local/lib/python3.11/site-packages (from pytorch-metric-learning) (2.3.0)\n",
      "Requirement already satisfied: tqdm in /home/ivbeveren/.local/lib/python3.11/site-packages (from pytorch-metric-learning) (4.66.4)\n",
      "Requirement already satisfied: filelock in /sw/arch/RHEL8/EB_production/2023/software/Python-bundle-PyPI/2023.06-GCCcore-12.3.0/lib/python3.11/site-packages (from torch>=1.6.0->pytorch-metric-learning) (3.12.2)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/ivbeveren/.local/lib/python3.11/site-packages (from torch>=1.6.0->pytorch-metric-learning) (4.11.0)\n",
      "Requirement already satisfied: sympy in /home/ivbeveren/.local/lib/python3.11/site-packages (from torch>=1.6.0->pytorch-metric-learning) (1.12)\n",
      "Requirement already satisfied: networkx in /home/ivbeveren/.local/lib/python3.11/site-packages (from torch>=1.6.0->pytorch-metric-learning) (3.3)\n",
      "Requirement already satisfied: jinja2 in /sw/arch/RHEL8/EB_production/2023/software/Python-bundle-PyPI/2023.06-GCCcore-12.3.0/lib/python3.11/site-packages (from torch>=1.6.0->pytorch-metric-learning) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /sw/arch/RHEL8/EB_production/2023/software/Python-bundle-PyPI/2023.06-GCCcore-12.3.0/lib/python3.11/site-packages (from torch>=1.6.0->pytorch-metric-learning) (2023.6.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/ivbeveren/.local/lib/python3.11/site-packages (from torch>=1.6.0->pytorch-metric-learning) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/ivbeveren/.local/lib/python3.11/site-packages (from torch>=1.6.0->pytorch-metric-learning) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/ivbeveren/.local/lib/python3.11/site-packages (from torch>=1.6.0->pytorch-metric-learning) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/ivbeveren/.local/lib/python3.11/site-packages (from torch>=1.6.0->pytorch-metric-learning) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/ivbeveren/.local/lib/python3.11/site-packages (from torch>=1.6.0->pytorch-metric-learning) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/ivbeveren/.local/lib/python3.11/site-packages (from torch>=1.6.0->pytorch-metric-learning) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/ivbeveren/.local/lib/python3.11/site-packages (from torch>=1.6.0->pytorch-metric-learning) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/ivbeveren/.local/lib/python3.11/site-packages (from torch>=1.6.0->pytorch-metric-learning) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/ivbeveren/.local/lib/python3.11/site-packages (from torch>=1.6.0->pytorch-metric-learning) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /home/ivbeveren/.local/lib/python3.11/site-packages (from torch>=1.6.0->pytorch-metric-learning) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/ivbeveren/.local/lib/python3.11/site-packages (from torch>=1.6.0->pytorch-metric-learning) (12.1.105)\n",
      "Requirement already satisfied: triton==2.3.0 in /home/ivbeveren/.local/lib/python3.11/site-packages (from torch>=1.6.0->pytorch-metric-learning) (2.3.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/ivbeveren/.local/lib/python3.11/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.6.0->pytorch-metric-learning) (12.4.127)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /sw/arch/RHEL8/EB_production/2023/software/SciPy-bundle/2023.07-gfbf-2023a/lib/python3.11/site-packages (from scikit-learn->pytorch-metric-learning) (1.11.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /sw/arch/RHEL8/EB_production/2023/software/Python-bundle-PyPI/2023.06-GCCcore-12.3.0/lib/python3.11/site-packages (from scikit-learn->pytorch-metric-learning) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /sw/arch/RHEL8/EB_production/2023/software/Python-bundle-PyPI/2023.06-GCCcore-12.3.0/lib/python3.11/site-packages (from scikit-learn->pytorch-metric-learning) (3.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /sw/arch/RHEL8/EB_production/2023/software/Mako/1.2.4-GCCcore-12.3.0/lib/python3.11/site-packages (from jinja2->torch>=1.6.0->pytorch-metric-learning) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /sw/arch/RHEL8/EB_production/2023/software/SciPy-bundle/2023.07-gfbf-2023a/lib/python3.11/site-packages (from sympy->torch>=1.6.0->pytorch-metric-learning) (1.3.0)\n",
      "Installing collected packages: pytorch-metric-learning\n",
      "Successfully installed pytorch-metric-learning-2.5.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install pytorch-metric-learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e1363677",
   "metadata": {},
   "outputs": [],
   "source": [
    "from speechbrain.dataio.dataset import DynamicItemDataset\n",
    "dataset_train = DynamicItemDataset.from_csv(\"UCLA-train.csv\") # or equivalently, DynamicItemDataset.from_csv(\"data.csv\")\n",
    "# dataset_val = DynamicItemDataset.from_csv(\"UCLA-val.csv\") # or equivalently, DynamicItemDataset.from_csv(\"data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "07800e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "@speechbrain.utils.data_pipeline.takes(\"path\", \"rescaled_speakerID\")\n",
    "@speechbrain.utils.data_pipeline.provides(\"signal1\", \"lab\")\n",
    "def audio_pipeline(path, rescaled_speakerID, max_duration=10):\n",
    "    waveform1, sample_rate1 = torchaudio.load(path.replace(\"\\\\\", \"/\"))\n",
    "\n",
    "    # feature_maker = Fbank(n_mels = 80, left_frames = 0, right_frames = 0, deltas = False)\n",
    "    # norm = InputNormalization(norm_type = 'sentence', std_norm = False, )\n",
    "\n",
    "    # Resample the audio to 16 kHz if needed\n",
    "    resampler = speechbrain.augment.time_domain.Resample(orig_freq=sample_rate1, new_freq=16000)\n",
    "    waveform1 = resampler(waveform1)\n",
    "    max_samples = int(max_duration * 16000)  # Maximum number of samples allowed\n",
    "    if waveform1.size(1) > max_samples:\n",
    "        waveform1 = waveform1[:, :max_samples]\n",
    "    \n",
    "    waveform1 = waveform1.transpose(0, 1).squeeze(1)\n",
    "\n",
    "    \n",
    "    # # Limit the duration if needed\n",
    "\n",
    "    \n",
    "    # features1 = feature_maker(waveform1)\n",
    "    \n",
    "    # inp_len1 = torch.Tensor([features1.shape[1]])\n",
    "    # features1 = norm(features1, inp_len1)\n",
    "\n",
    "\n",
    "\n",
    "    return waveform1, int(rescaled_speakerID)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "b39ed748",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torchaudio.load('UCLA\\\\001\\\\1A_instructions.wav')\n",
    "os.path.isfile('UCLA/001/1A_instructions.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f95fd393",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train.add_dynamic_item(audio_pipeline)\n",
    "# dataset_val.add_dynamic_item(audio_pipeline)\n",
    "\n",
    "dataset_train.set_output_keys([\"signal1\", \"lab\"])\n",
    "# dataset_val.set_output_keys([\"signal1\", \"lab\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "61430eaa-0df0-4966-8328-4640b1d2a3af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1098"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "120c8915",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# labels = [item['lab'] for item in dataset]\n",
    "# print(labels)\n",
    "# Perform train, validation, and test split\n",
    "# labels = [data['lab'] for data in dataset]\n",
    "train_data, val_data = train_test_split(dataset_train, test_size=0.2, random_state=42)\n",
    "# val_data, test_data = train_test_split(temp_data, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "6a6a9f1b-00ce-4897-8617-23fac0c2b444",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from speechbrain.dataio.dataset import DynamicItemDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "# Group indices by label\n",
    "label_to_indices_train = defaultdict(list)\n",
    "for idx, data in enumerate(train_data):\n",
    "    label = data['lab']\n",
    "    label_to_indices_train[label].append(idx)\n",
    "\n",
    "label_to_indices_val = defaultdict(list)\n",
    "for idx, data in enumerate(val_data):\n",
    "    label = data['lab']\n",
    "    label_to_indices_val[label].append(idx)\n",
    "import numpy as np\n",
    "\n",
    "def create_batches(label_to_indices, batch_size):\n",
    "    batches = []\n",
    "    for label, indices in label_to_indices.items():\n",
    "        np.random.shuffle(indices)  # Shuffle to ensure randomness\n",
    "        for i in range(0, len(indices), 2):\n",
    "            if i + 1 < len(indices):\n",
    "                batch = indices[i:i+2]\n",
    "                # Fill the rest of the batch with random pairs\n",
    "                while len(batch) < batch_size:\n",
    "                    rand_label = np.random.choice(list(label_to_indices.keys()))\n",
    "                    if len(label_to_indices[rand_label]) >= 2:\n",
    "                        rand_indices = np.random.choice(label_to_indices[rand_label], 2, replace=False).tolist()\n",
    "                    else:\n",
    "                        rand_indices = np.random.choice(label_to_indices[rand_label], 2, replace=True).tolist()\n",
    "                    batch.extend(rand_indices[:batch_size - len(batch)])  # Ensure batch size is not exceeded\n",
    "                batches.append(batch)\n",
    "    return batches\n",
    "batches_train = create_batches(label_to_indices_train, batch_size=16)\n",
    "batches_val = create_batches(label_to_indices_val, batch_size=16)\n",
    "from torch.utils.data import Sampler\n",
    "\n",
    "class CustomBatchSampler(Sampler):\n",
    "    def __init__(self, batches):\n",
    "        self.batches = batches\n",
    "    \n",
    "    def __iter__(self):\n",
    "        np.random.shuffle(self.batches)\n",
    "        for batch in self.batches:\n",
    "            yield batch\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.batches)\n",
    "\n",
    "custom_batch_sampler_train = CustomBatchSampler(batches_train)\n",
    "custom_batch_sampler_val = CustomBatchSampler(batches_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "add283c5",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'DataLoader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mspeechbrain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdataio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdataloader\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SaveableDataLoader\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mspeechbrain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdataio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbatch\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PaddedBatch\n\u001b[0;32m----> 4\u001b[0m dataloader_train \u001b[38;5;241m=\u001b[39m \u001b[43mDataLoader\u001b[49m(train_data, batch_sampler\u001b[38;5;241m=\u001b[39mcustom_batch_sampler_train, collate_fn\u001b[38;5;241m=\u001b[39mPaddedBatch)\n\u001b[1;32m      5\u001b[0m dataloader_val \u001b[38;5;241m=\u001b[39m DataLoader(val_data, batch_sampler\u001b[38;5;241m=\u001b[39mcustom_batch_sampler_val, collate_fn\u001b[38;5;241m=\u001b[39mPaddedBatch)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'DataLoader' is not defined"
     ]
    }
   ],
   "source": [
    "from speechbrain.dataio.dataloader import SaveableDataLoader\n",
    "from speechbrain.dataio.batch import PaddedBatch\n",
    "\n",
    "dataloader_train = DataLoader(train_data, batch_sampler=custom_batch_sampler_train, collate_fn=PaddedBatch)\n",
    "dataloader_val = DataLoader(val_data, batch_sampler=custom_batch_sampler_val, collate_fn=PaddedBatch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "0b2cda05-8175-49cf-b1fe-0b748c7b89e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([163, 163,  59,  59,  91,  91, 111, 111, 121, 121,  75,  75,   4,   4,\n",
      "         14,  14])\n",
      "tensor([ 26,  26,   1,   1,  80,  80,  83,  83, 164, 164,  31,  31,  45,  45,\n",
      "        125, 125])\n",
      "tensor([112, 112,  26,  26, 162, 162, 141, 141, 123, 123,  31,  31, 172, 172,\n",
      "         54,  54])\n",
      "tensor([ 76,  76,  14,  14, 139, 139, 102, 102,  18,  18, 131, 131,  53,  53,\n",
      "         88,  88])\n",
      "tensor([ 77,  77, 171, 171,  95,  95, 143, 143, 144, 144,   0,   0,  83,  83,\n",
      "        148, 148])\n",
      "tensor([ 46,  46, 133, 133,  62,  62,   6,   6, 112, 112, 170, 170, 165, 165,\n",
      "         31,  31])\n",
      "tensor([109, 109,  37,  37,  35,  35,  13,  13, 124, 124,  96,  96, 150, 150,\n",
      "         37,  37])\n",
      "tensor([113, 113, 114, 114, 104, 104, 125, 125,  31,  31, 105, 105, 119, 119,\n",
      "         50,  50])\n",
      "tensor([165, 165,  41,  41, 110, 110,  37,  37,  13,  13, 161, 161,  94,  94,\n",
      "         68,  68])\n",
      "tensor([ 28,  28, 171, 171, 136, 136,   2,   2,  53,  53,  53,  53,  25,  25,\n",
      "        114, 114])\n",
      "tensor([ 52,  52, 147, 147,  36,  36,  62,  62, 163, 163,  42,  42, 142, 142,\n",
      "        158, 158])\n",
      "tensor([ 77,  77,  31,  31, 114, 114, 111, 111,  81,  81, 156, 156,  28,  28,\n",
      "         58,  58])\n",
      "tensor([ 21,  21,  60,  60,  94,  94, 171, 171, 168, 168,  66,  66,  22,  22,\n",
      "        102, 102])\n",
      "tensor([148, 148, 122, 122,  51,  51, 159, 159,  53,  53,   7,   7,  46,  46,\n",
      "        126, 126])\n",
      "tensor([115, 115,  42,  42,  84,  84, 109, 109,  74,  74,  51,  51, 138, 138,\n",
      "         45,  45])\n",
      "tensor([162, 162, 153, 153, 142, 142,   2,   2,   2,   2, 140, 140,  57,  57,\n",
      "         61,  61])\n",
      "tensor([ 64,  64,  73,  73,  89,  89,   3,   3,  52,  52,  91,  91, 143, 143,\n",
      "         77,  77])\n",
      "tensor([  6,   6,  74,  74, 142, 142,  85,  85, 161, 161,   8,   8, 129, 129,\n",
      "         29,  29])\n",
      "tensor([100, 100, 122, 122, 161, 161,  45,  45, 161, 161,  28,  28,  38,  38,\n",
      "         14,  14])\n",
      "tensor([172, 172, 161, 161, 108, 108, 136, 136,  38,  38,  24,  24, 156, 156,\n",
      "         64,  64])\n",
      "tensor([  2,   2,  79,  79, 138, 138,  11,  11,  46,  46,  66,  66, 137, 137,\n",
      "         11,  11])\n",
      "tensor([101, 101, 101, 101,   0,   0,  84,  84, 155, 155, 120, 120, 145, 145,\n",
      "         77,  77])\n",
      "tensor([ 27,  27,  61,  61,  62,  62,  10,  10, 102, 102,  62,  62, 107, 107,\n",
      "        166, 166])\n",
      "tensor([ 47,  47, 134, 134, 136, 136,  16,  16, 127, 127, 121, 121,  47,  47,\n",
      "         15,  15])\n",
      "tensor([ 17,  17,   3,   3,  88,  88,  95,  95,  62,  62,  77,  77, 162, 162,\n",
      "         49,  49])\n",
      "tensor([ 34,  34, 118, 118,  60,  60, 110, 110, 173, 173,  94,  94,  75,  75,\n",
      "         84,  84])\n",
      "tensor([155, 155, 125, 125, 131, 131,  65,  65, 136, 136,   2,   2, 103, 103,\n",
      "        138, 138])\n",
      "tensor([ 91,  91,   8,   8, 142, 142, 121, 121, 167, 167,  69,  69, 150, 150,\n",
      "         36,  36])\n",
      "tensor([ 68,  68,  66,  66,  15,  15,  27,  27, 102, 102,  69,  69,  52,  52,\n",
      "        167, 167])\n",
      "tensor([116, 116, 130, 130,  45,  45, 124, 124,   3,   3, 162, 162, 160, 160,\n",
      "         33,  33])\n",
      "tensor([158, 158, 133, 133, 119, 119, 107, 107, 120, 120,  58,  58, 108, 108,\n",
      "        167, 167])\n",
      "tensor([119, 119, 125, 125,  59,  59, 128, 128, 110, 110,  68,  68,   0,   0,\n",
      "         85,  85])\n",
      "tensor([ 99,  99, 171, 171,  72,  72, 151, 151, 160, 160, 160, 160, 128, 128,\n",
      "        103, 103])\n",
      "tensor([167, 167,  53,  53, 135, 135, 171, 171, 126, 126, 146, 146,  83,  83,\n",
      "         96,  96])\n",
      "tensor([114, 114,  34,  34,  98,  98, 102, 102,  43,  43,  98,  98,   5,   5,\n",
      "         36,  36])\n",
      "tensor([ 42,  42,  93,  93,  89,  89,  24,  24, 128, 128, 163, 163,  99,  99,\n",
      "          5,   5])\n",
      "tensor([  8,   8,   3,   3, 110, 110, 161, 161, 120, 120,  74,  74,  19,  19,\n",
      "         43,  43])\n",
      "tensor([136, 136,   3,   3, 115, 115,   4,   4,   3,   3,   4,   4,   8,   8,\n",
      "         33,  33])\n",
      "tensor([120, 120, 112, 112,  56,  56, 102, 102, 156, 156,  85,  85,  44,  44,\n",
      "         90,  90])\n",
      "tensor([ 49,  49, 119, 119, 106, 106, 146, 146, 111, 111, 165, 165, 126, 126,\n",
      "          2,   2])\n",
      "tensor([ 32,  32,  86,  86,  32,  32, 101, 101, 128, 128, 170, 170,  35,  35,\n",
      "          8,   8])\n",
      "tensor([ 10,  10,  80,  80, 115, 115,  90,  90,  45,  45,  99,  99,  37,  37,\n",
      "         45,  45])\n",
      "tensor([107, 107,  67,  67,  67,  67,  23,  23,  28,  28,  68,  68,  34,  34,\n",
      "        119, 119])\n",
      "tensor([172, 172, 136, 136,  41,  41, 164, 164,  24,  24, 130, 130, 111, 111,\n",
      "        154, 154])\n",
      "tensor([111, 111, 162, 162,  87,  87,  40,  40,  55,  55,  42,  42,  54,  54,\n",
      "         77,  77])\n",
      "tensor([105, 105,  44,  44,  48,  48,  62,  62, 101, 101, 167, 167, 109, 109,\n",
      "         75,  75])\n",
      "tensor([ 60,  60, 112, 112,  47,  47,  29,  29, 109, 109,  56,  56, 161, 161,\n",
      "         68,  68])\n",
      "tensor([ 50,  50,   1,   1,  10,  10,  29,  29, 141, 141, 161, 161,  17,  17,\n",
      "        155, 155])\n",
      "tensor([ 44,  44,  22,  22,  24,  24, 122, 122, 155, 155, 123, 123,  99,  99,\n",
      "          6,   6])\n",
      "tensor([132, 132,  44,  44,  46,  46, 104, 104, 101, 101, 166, 166,  77,  77,\n",
      "         37,  37])\n",
      "tensor([153, 153, 148, 148, 143, 143,  90,  90,  29,  29, 117, 117, 149, 149,\n",
      "        123, 123])\n",
      "tensor([139, 139, 112, 112,  30,  30,   0,   0, 127, 127,  86,  86, 126, 126,\n",
      "        150, 150])\n",
      "tensor([108, 108, 155, 155,  67,  67, 121, 121,  71,  71,  81,  81,  40,  40,\n",
      "         56,  56])\n",
      "tensor([ 28,  28, 142, 142, 153, 153,  20,  20, 119, 119,  60,  60,  77,  77,\n",
      "        152, 152])\n",
      "tensor([140, 140,  85,  85, 150, 150,   1,   1,  29,  29,  30,  30,   0,   0,\n",
      "         10,  10])\n",
      "tensor([ 64,  64,  84,  84, 124, 124,  43,  43, 172, 172, 128, 128,  40,  40,\n",
      "         57,  57])\n",
      "tensor([140, 140,  99,  99,  54,  54,  49,  49, 131, 131,  87,  87, 102, 102,\n",
      "         33,  33])\n",
      "tensor([ 55,  55, 103, 103, 139, 139,  33,  33,  55,  55, 105, 105,  74,  74,\n",
      "         72,  72])\n",
      "tensor([ 86,  86,  83,  83, 113, 113,  65,  65,  62,  62, 101, 101,  92,  92,\n",
      "        117, 117])\n",
      "tensor([162, 162, 155, 155, 120, 120,  51,  51,  96,  96,  74,  74, 154, 154,\n",
      "         59,  59])\n",
      "tensor([134, 134,  91,  91,  89,  89, 105, 105, 170, 170, 129, 129, 118, 118,\n",
      "         55,  55])\n",
      "tensor([129, 129, 139, 139, 172, 172,  34,  34, 114, 114,  91,  91, 168, 168,\n",
      "        137, 137])\n",
      "tensor([ 90,  90, 131, 131, 136, 136, 124, 124, 124, 124, 166, 166, 152, 152,\n",
      "        143, 143])\n",
      "tensor([ 30,  30, 166, 166,  55,  55, 137, 137, 121, 121,  55,  55,  15,  15,\n",
      "        114, 114])\n",
      "tensor([152, 152, 144, 144,  68,  68,  91,  91,  79,  79,   2,   2,  31,  31,\n",
      "        145, 145])\n",
      "tensor([78, 78, 99, 99, 42, 42, 28, 28, 82, 82, 26, 26, 21, 21, 67, 67])\n",
      "tensor([145, 145, 127, 127,  37,  37,  52,  52, 116, 116,  48,  48,  12,  12,\n",
      "         40,  40])\n",
      "tensor([ 99,  99,  95,  95, 126, 126, 112, 112,  37,  37,  70,  70,  46,  46,\n",
      "         41,  41])\n",
      "tensor([119, 119,  69,  69,  86,  86,  87,  87, 153, 153, 145, 145, 170, 170,\n",
      "         48,  48])\n",
      "tensor([  3,   3,  68,  68, 171, 171,   4,   4,  97,  97,  95,  95,   1,   1,\n",
      "         59,  59])\n",
      "tensor([142, 142,  70,  70,  45,  45,  62,  62,  65,  65, 150, 150, 105, 105,\n",
      "         17,  17])\n",
      "tensor([ 36,  36, 162, 162, 162, 162, 172, 172,  83,  83,  28,  28, 151, 151,\n",
      "         56,  56])\n",
      "tensor([120, 120, 131, 131, 170, 170, 134, 134,  52,  52,  32,  32,   8,   8,\n",
      "         10,  10])\n",
      "tensor([ 93,  93, 116, 116,  15,  15, 119, 119, 167, 167,   9,   9,  91,  91,\n",
      "         25,  25])\n",
      "tensor([ 52,  52, 144, 144,  69,  69, 141, 141, 167, 167, 170, 170,  12,  12,\n",
      "         42,  42])\n",
      "tensor([ 99,  99,   2,   2, 158, 158,  44,  44,  94,  94,  54,  54, 162, 162,\n",
      "        154, 154])\n",
      "tensor([146, 146,  36,  36,   6,   6,  97,  97,  62,  62, 111, 111, 105, 105,\n",
      "         64,  64])\n",
      "tensor([ 13,  13,  17,  17,  55,  55,  64,  64, 135, 135,  40,  40,  63,  63,\n",
      "         36,  36])\n",
      "tensor([125, 125,   5,   5,  97,  97,  29,  29, 101, 101,   1,   1,  80,  80,\n",
      "        171, 171])\n",
      "tensor([ 28,  28,  35,  35,  58,  58, 111, 111, 154, 154,  13,  13,  16,  16,\n",
      "        130, 130])\n",
      "tensor([145, 145, 124, 124,  15,  15, 156, 156, 170, 170,  82,  82, 160, 160,\n",
      "         45,  45])\n",
      "tensor([157, 157,  10,  10,  65,  65, 110, 110,  55,  55,  50,  50,  38,  38,\n",
      "         17,  17])\n",
      "tensor([  6,   6,  81,  81,  12,  12, 136, 136,  32,  32, 133, 133, 146, 146,\n",
      "         59,  59])\n",
      "tensor([110, 110,  94,  94,  77,  77, 167, 167,   5,   5, 165, 165, 115, 115,\n",
      "        172, 172])\n",
      "tensor([ 94,  94, 170, 170,   1,   1,  40,  40, 107, 107,  29,  29,  21,  21,\n",
      "         52,  52])\n",
      "tensor([ 45,  45, 119, 119,  92,  92,  94,  94,  68,  68,  42,  42,  76,  76,\n",
      "        109, 109])\n",
      "tensor([159, 159, 113, 113, 166, 166, 102, 102,   0,   0,  20,  20,  36,  36,\n",
      "        154, 154])\n",
      "tensor([ 33,  33,  45,  45,  49,  49,  76,  76,  81,  81,  94,  94, 112, 112,\n",
      "         76,  76])\n",
      "tensor([ 85,  85,  56,  56,  59,  59,  18,  18,  67,  67,  92,  92, 123, 123,\n",
      "         55,  55])\n",
      "tensor([ 71,  71,  73,  73,  86,  86,   7,   7,  44,  44, 141, 141, 161, 161,\n",
      "        134, 134])\n",
      "tensor([169, 169,  50,  50,   1,   1,  83,  83, 108, 108,   1,   1, 126, 126,\n",
      "        172, 172])\n",
      "tensor([102, 102,   2,   2,  86,  86, 114, 114,  24,  24,  96,  96,   9,   9,\n",
      "        124, 124])\n",
      "tensor([ 85,  85, 121, 121, 104, 104, 148, 148,  37,  37, 132, 132, 142, 142,\n",
      "        158, 158])\n",
      "tensor([137, 137, 171, 171,  65,  65, 167, 167,  61,  61, 165, 165,  51,  51,\n",
      "        142, 142])\n",
      "tensor([ 14,  14, 111, 111,  19,  19, 150, 150, 134, 134,   8,   8, 135, 135,\n",
      "         42,  42])\n",
      "tensor([ 63,  63,  38,  38, 109, 109,  58,  58, 113, 113, 137, 137, 152, 152,\n",
      "         81,  81])\n",
      "tensor([ 82,  82,  64,  64,  92,  92, 131, 131, 154, 154,  44,  44, 101, 101,\n",
      "         24,  24])\n",
      "tensor([171, 171,   4,   4,  15,  15,   6,   6,  62,  62,  38,  38,  61,  61,\n",
      "         54,  54])\n",
      "tensor([161, 161,  28,  28,  93,  93,  40,  40, 129, 129, 166, 166,  56,  56,\n",
      "         76,  76])\n",
      "tensor([ 19,  19, 122, 122,  12,  12,  97,  97, 167, 167,  92,  92,  80,  80,\n",
      "         34,  34])\n",
      "tensor([ 47,  47, 138, 138, 170, 170, 106, 106, 148, 148,  53,  53, 149, 149,\n",
      "        112, 112])\n",
      "tensor([168, 168, 163, 163, 106, 106,  70,  70, 171, 171,  47,  47,   2,   2,\n",
      "         13,  13])\n",
      "tensor([ 41,  41, 101, 101,  40,  40,   5,   5,  39,  39,  16,  16,  53,  53,\n",
      "        158, 158])\n",
      "tensor([ 92,  92, 153, 153,  94,  94,  34,  34,  56,  56, 109, 109,  55,  55,\n",
      "        141, 141])\n",
      "tensor([137, 137, 106, 106, 120, 120, 151, 151, 107, 107,  34,  34,  87,  87,\n",
      "         49,  49])\n",
      "tensor([ 19,  19,  77,  77,  20,  20,  29,  29,  36,  36, 167, 167,  34,  34,\n",
      "        145, 145])\n",
      "tensor([141, 141, 140, 140,  12,  12,  72,  72,  75,  75,  65,  65,  68,  68,\n",
      "         42,  42])\n",
      "tensor([ 36,  36,  33,  33, 127, 127,  83,  83,  47,  47, 113, 113, 120, 120,\n",
      "          2,   2])\n",
      "tensor([ 63,  63, 116, 116, 111, 111,  70,  70, 159, 159,  94,  94, 113, 113,\n",
      "          5,   5])\n",
      "tensor([ 48,  48,  11,  11,  14,  14, 111, 111,   5,   5, 146, 146,  14,  14,\n",
      "         76,  76])\n",
      "tensor([ 56,  56, 144, 144,  75,  75,  56,  56, 127, 127,  21,  21, 101, 101,\n",
      "        110, 110])\n",
      "tensor([ 70,  70, 166, 166,  14,  14,  80,  80, 138, 138, 135, 135,  92,  92,\n",
      "          1,   1])\n",
      "tensor([ 92,  92, 140, 140,   1,   1, 118, 118, 116, 116,  73,  73,  45,  45,\n",
      "         66,  66])\n",
      "tensor([ 24,  24,  38,  38, 156, 156,  54,  54,  23,  23,   0,   0, 169, 169,\n",
      "         21,  21])\n",
      "tensor([ 79,  79,  84,  84,  75,  75, 160, 160,  87,  87, 156, 156, 166, 166,\n",
      "         45,  45])\n",
      "tensor([164, 164, 125, 125, 107, 107, 169, 169,  81,  81,  46,  46,   3,   3,\n",
      "         93,  93])\n",
      "tensor([132, 132,  59,  59, 171, 171, 144, 144,  88,  88, 145, 145,  82,  82,\n",
      "         76,  76])\n",
      "tensor([ 74,  74,  89,  89, 141, 141, 108, 108, 104, 104,  20,  20,  90,  90,\n",
      "         39,  39])\n",
      "tensor([ 27,  27, 143, 143,  27,  27,  76,  76,  11,  11,  82,  82, 128, 128,\n",
      "          9,   9])\n",
      "tensor([ 81,  81, 168, 168, 126, 126, 112, 112, 134, 134,  91,  91,  95,  95,\n",
      "         39,  39])\n",
      "tensor([  0,   0,  24,  24, 138, 138,  29,  29,  61,  61, 118, 118, 112, 112,\n",
      "        134, 134])\n",
      "tensor([ 92,  92,  26,  26,  62,  62,  39,  39, 154, 154,  85,  85,  67,  67,\n",
      "         24,  24])\n",
      "tensor([  4,   4, 148, 148,  66,  66, 121, 121,  19,  19, 142, 142, 130, 130,\n",
      "        135, 135])\n",
      "tensor([106, 106, 150, 150, 110, 110, 143, 143,  43,  43,  38,  38, 134, 134,\n",
      "         73,  73])\n",
      "tensor([ 78,  78,  94,  94,  54,  54,  28,  28, 167, 167,  38,  38, 111, 111,\n",
      "         40,  40])\n",
      "tensor([140, 140,   9,   9, 121, 121, 162, 162,  30,  30, 110, 110,  39,  39,\n",
      "         88,  88])\n",
      "tensor([113, 113, 114, 114,  50,  50, 135, 135,  90,  90,  53,  53,   7,   7,\n",
      "         54,  54])\n",
      "tensor([125, 125, 104, 104, 123, 123,  15,  15,   6,   6, 172, 172, 115, 115,\n",
      "         54,  54])\n",
      "tensor([ 80,  80,  47,  47,  46,  46,  62,  62,  96,  96, 126, 126,  42,  42,\n",
      "        112, 112])\n",
      "tensor([ 66,  66, 121, 121,   6,   6,  75,  75, 107, 107,  54,  54,  41,  41,\n",
      "        169, 169])\n",
      "tensor([133, 133,  56,  56, 107, 107, 171, 171, 123, 123,   9,   9, 160, 160,\n",
      "         39,  39])\n",
      "tensor([ 25,  25,  37,  37,  25,  25, 117, 117,   7,   7,  91,  91,  76,  76,\n",
      "        171, 171])\n",
      "tensor([160, 160,  61,  61,  83,  83,  14,  14,  58,  58, 150, 150,  11,  11,\n",
      "         56,  56])\n",
      "tensor([108, 108, 167, 167,  61,  61,   3,   3, 142, 142, 149, 149,  64,  64,\n",
      "          3,   3])\n",
      "tensor([  7,   7,  93,  93, 172, 172, 130, 130,  18,  18,   2,   2, 127, 127,\n",
      "        106, 106])\n",
      "tensor([152, 152, 164, 164, 143, 143,  36,  36, 148, 148,  90,  90, 125, 125,\n",
      "        133, 133])\n",
      "tensor([ 94,  94, 121, 121,  72,  72,  84,  84, 143, 143,   1,   1,  86,  86,\n",
      "        126, 126])\n",
      "tensor([129, 129,  72,  72,  50,  50,  35,  35, 139, 139, 115, 115, 142, 142,\n",
      "         76,  76])\n",
      "tensor([156, 156, 143, 143,  81,  81, 120, 120, 104, 104,  30,  30, 123, 123,\n",
      "        133, 133])\n",
      "tensor([143, 143,   1,   1,  67,  67,   2,   2,   9,   9,  23,  23,  35,  35,\n",
      "         18,  18])\n",
      "tensor([35, 35, 43, 43, 44, 44, 75, 75, 74, 74, 59, 59, 21, 21, 69, 69])\n",
      "tensor([107, 107,   3,   3, 106, 106, 127, 127, 131, 131,  73,  73,  52,  52,\n",
      "        100, 100])\n",
      "tensor([150, 150, 167, 167,  99,  99,  91,  91,  88,  88,   5,   5, 165, 165,\n",
      "          7,   7])\n",
      "tensor([  3,   3, 140, 140,  37,  37, 125, 125,  63,  63, 110, 110, 167, 167,\n",
      "         49,  49])\n",
      "tensor([114, 114, 146, 146,  56,  56, 131, 131, 154, 154, 153, 153,  57,  57,\n",
      "         51,  51])\n",
      "tensor([ 93,  93,   7,   7,  76,  76, 147, 147,  67,  67, 115, 115, 131, 131,\n",
      "        124, 124])\n",
      "tensor([ 40,  40,  99,  99, 160, 160, 166, 166, 138, 138,   7,   7, 104, 104,\n",
      "         28,  28])\n",
      "tensor([ 79,  79, 112, 112, 123, 123,  58,  58,  86,  86,  13,  13,  64,  64,\n",
      "         63,  63])\n",
      "tensor([ 68,  68,  21,  21, 136, 136, 173, 173,   4,   4,  98,  98, 152, 152,\n",
      "         62,  62])\n",
      "tensor([163, 163, 134, 134,  59,  59,   7,   7, 150, 150, 133, 133, 158, 158,\n",
      "        133, 133])\n",
      "tensor([ 89,  89, 115, 115,  44,  44,  84,  84, 112, 112,  50,  50,  68,  68,\n",
      "         57,  57])\n",
      "tensor([ 37,  37, 171, 171, 132, 132, 154, 154, 163, 163, 169, 169, 169, 169,\n",
      "         11,  11])\n",
      "tensor([134, 134,  54,  54,  89,  89,  79,  79, 151, 151, 146, 146,  62,  62,\n",
      "         80,  80])\n",
      "tensor([ 58,  58,  61,  61, 156, 156, 113, 113, 151, 151,  20,  20, 162, 162,\n",
      "        154, 154])\n",
      "tensor([ 22,  22, 156, 156,  14,  14, 134, 134,  49,  49, 147, 147, 159, 159,\n",
      "         86,  86])\n",
      "tensor([126, 126,  57,  57, 157, 157,  46,  46,  70,  70,  99,  99,  49,  49,\n",
      "         68,  68])\n",
      "tensor([166, 166, 169, 169,  60,  60,  23,  23, 171, 171,  43,  43, 159, 159,\n",
      "        132, 132])\n",
      "tensor([ 19,  19,   1,   1,  86,  86, 112, 112,  40,  40, 171, 171,  73,  73,\n",
      "        150, 150])\n",
      "tensor([130, 130,  11,  11,  48,  48, 103, 103,  99,  99, 111, 111, 106, 106,\n",
      "        159, 159])\n",
      "tensor([ 35,  35, 161, 161, 101, 101,  64,  64,  65,  65,  56,  56, 158, 158,\n",
      "        138, 138])\n",
      "tensor([ 76,  76,  13,  13,   2,   2,  93,  93, 165, 165,  26,  26,  90,  90,\n",
      "         95,  95])\n",
      "tensor([167, 167, 159, 159,  53,  53,  59,  59,   0,   0,  88,  88,  76,  76,\n",
      "         95,  95])\n",
      "tensor([ 20,  20, 105, 105, 149, 149,  78,  78, 101, 101,  84,  84, 107, 107,\n",
      "         55,  55])\n",
      "tensor([ 22,  22, 168, 168,  25,  25,  93,  93,  39,  39,  60,  60,  61,  61,\n",
      "        134, 134])\n",
      "tensor([109, 109,  68,  68, 147, 147, 131, 131,  72,  72,  41,  41,  41,  41,\n",
      "         37,  37])\n",
      "tensor([156, 156, 149, 149,  18,  18,  72,  72,  66,  66,  66,  66, 118, 118,\n",
      "         13,  13])\n",
      "tensor([117, 117, 143, 143,  81,  81,  18,  18,  25,  25,  85,  85,  73,  73,\n",
      "        109, 109])\n",
      "tensor([ 83,  83, 154, 154,  88,  88, 111, 111,   9,   9, 150, 150,   2,   2,\n",
      "        168, 168])\n",
      "tensor([ 44,  44, 117, 117,  72,  72,  93,  93,  74,  74,  73,  73, 154, 154,\n",
      "        166, 166])\n",
      "tensor([169, 169,  31,  31,  85,  85,   3,   3,  10,  10, 114, 114,  58,  58,\n",
      "         63,  63])\n",
      "tensor([ 99,  99,  52,  52, 150, 150,  19,  19,  46,  46,  53,  53,  72,  72,\n",
      "         56,  56])\n",
      "tensor([128, 128,  30,  30,  29,  29, 100, 100,   8,   8, 135, 135, 156, 156,\n",
      "         64,  64])\n",
      "tensor([ 73,  73,  38,  38, 125, 125, 117, 117,  67,  67,  96,  96,  79,  79,\n",
      "        106, 106])\n",
      "tensor([111, 111, 173, 173, 165, 165, 145, 145,   9,   9,  40,  40,   1,   1,\n",
      "        105, 105])\n",
      "tensor([ 95,  95,  83,  83,   2,   2,  95,  95, 108, 108, 160, 160,  68,  68,\n",
      "        126, 126])\n",
      "tensor([137, 137,  32,  32, 134, 134,  27,  27,  18,  18,  20,  20,  31,  31,\n",
      "        163, 163])\n",
      "tensor([ 35,  35,  38,  38, 154, 154, 117, 117,  87,  87,  84,  84,  25,  25,\n",
      "         52,  52])\n",
      "tensor([121, 121,  43,  43,  90,  90,  83,  83, 114, 114, 148, 148,  58,  58,\n",
      "         82,  82])\n",
      "tensor([ 15,  15,  26,  26,  52,  52, 163, 163, 132, 132,  57,  57, 107, 107,\n",
      "        151, 151])\n",
      "tensor([136, 136,  62,  62,  27,  27, 159, 159,  58,  58, 165, 165,  78,  78,\n",
      "         23,  23])\n",
      "tensor([130, 130, 109, 109, 106, 106, 167, 167, 103, 103, 165, 165, 162, 162,\n",
      "         43,  43])\n",
      "tensor([ 33,  33,   0,   0, 165, 165,   3,   3,  38,  38,  80,  80, 163, 163,\n",
      "         89,  89])\n",
      "tensor([122, 122,  91,  91, 106, 106,  99,  99, 156, 156, 171, 171,  77,  77,\n",
      "         64,  64])\n",
      "tensor([ 73,  73,  49,  49,  68,  68, 108, 108, 162, 162, 161, 161,  54,  54,\n",
      "         92,  92])\n",
      "tensor([ 67,  67, 148, 148,  76,  76, 120, 120,  66,  66, 121, 121, 122, 122,\n",
      "        141, 141])\n",
      "tensor([165, 165, 158, 158, 107, 107, 118, 118,   0,   0, 142, 142,  80,  80,\n",
      "        134, 134])\n",
      "tensor([154, 154,  66,  66,  85,  85,   5,   5, 123, 123, 105, 105,  61,  61,\n",
      "        157, 157])\n",
      "tensor([ 96,  96,  59,  59,  51,  51, 110, 110,  86,  86,  18,  18, 136, 136,\n",
      "         32,  32])\n",
      "tensor([ 16,  16,  55,  55,  67,  67, 118, 118,  77,  77, 170, 170, 138, 138,\n",
      "          2,   2])\n",
      "tensor([ 53,  53,   8,   8, 109, 109,  46,  46,  84,  84,  77,  77,   8,   8,\n",
      "         65,  65])\n",
      "tensor([ 87,  87, 141, 141, 130, 130, 138, 138, 114, 114,  64,  64, 163, 163,\n",
      "        116, 116])\n",
      "tensor([127, 127,  44,  44, 157, 157, 109, 109,  97,  97, 163, 163, 112, 112,\n",
      "         22,  22])\n",
      "tensor([ 29,  29,  68,  68,  88,  88,   1,   1,  97,  97, 152, 152, 122, 122,\n",
      "        112, 112])\n",
      "tensor([ 55,  55, 132, 132, 168, 168,  65,  65, 133, 133,   7,   7, 104, 104,\n",
      "         84,  84])\n",
      "tensor([171, 171,  73,  73,   2,   2,  49,  49,  50,  50,  39,  39,  47,  47,\n",
      "         54,  54])\n",
      "tensor([ 23,  23,  48,  48, 138, 138,  20,  20,  84,  84,   1,   1, 109, 109,\n",
      "         61,  61])\n",
      "tensor([  7,   7, 101, 101, 151, 151, 116, 116,  40,  40,  69,  69,  70,  70,\n",
      "          4,   4])\n",
      "tensor([ 37,  37, 164, 164, 105, 105,  93,  93, 112, 112,   4,   4,  93,  93,\n",
      "         48,  48])\n",
      "tensor([ 31,  31, 107, 107,  64,  64, 108, 108,  80,  80,  69,  69, 117, 117,\n",
      "         78,  78])\n",
      "tensor([ 80,  80,  28,  28, 104, 104,  56,  56,  38,  38,  27,  27, 136, 136,\n",
      "         33,  33])\n",
      "tensor([ 48,  48, 140, 140,  80,  80,  45,  45, 117, 117, 124, 124,  28,  28,\n",
      "         34,  34])\n",
      "tensor([ 15,  15, 166, 166,   7,   7,   1,   1,  10,  10,  13,  13, 113, 113,\n",
      "        143, 143])\n",
      "tensor([113, 113, 113, 113, 142, 142,   9,   9, 149, 149, 126, 126,  95,  95,\n",
      "        154, 154])\n",
      "tensor([ 17,  17,  60,  60, 155, 155, 109, 109, 120, 120,  96,  96,  56,  56,\n",
      "          0,   0])\n",
      "tensor([  5,   5,  63,  63, 155, 155, 131, 131, 112, 112,  84,  84,  24,  24,\n",
      "         90,  90])\n",
      "tensor([ 49,  49,  42,  42, 112, 112, 138, 138, 117, 117,   5,   5,   4,   4,\n",
      "        173, 173])\n",
      "tensor([ 92,  92, 142, 142, 119, 119, 166, 166, 132, 132,  38,  38, 125, 125,\n",
      "         83,  83])\n",
      "tensor([110, 110,  79,  79, 167, 167,  25,  25,  57,  57, 126, 126, 100, 100,\n",
      "         83,  83])\n",
      "tensor([148, 148,   5,   5,  36,  36, 138, 138, 165, 165, 166, 166,  88,  88,\n",
      "        168, 168])\n",
      "tensor([ 39,  39,  68,  68, 161, 161,  39,  39, 172, 172,  20,  20, 136, 136,\n",
      "         45,  45])\n",
      "tensor([173, 173,  60,  60,  26,  26,  30,  30,  21,  21, 109, 109,  79,  79,\n",
      "         29,  29])\n",
      "tensor([103, 103,  88,  88,  25,  25,  90,  90,  33,  33, 122, 122, 110, 110,\n",
      "         94,  94])\n",
      "tensor([168, 168,  85,  85,  83,  83,  85,  85,   8,   8, 107, 107, 101, 101,\n",
      "         39,  39])\n",
      "tensor([125, 125, 145, 145, 130, 130,  86,  86,  85,  85,  90,  90,   2,   2,\n",
      "        160, 160])\n",
      "tensor([155, 155,  76,  76,  25,  25,  28,  28,  37,  37,  62,  62,  14,  14,\n",
      "         84,  84])\n",
      "tensor([173, 173,  77,  77,  37,  37,  61,  61, 116, 116, 117, 117, 173, 173,\n",
      "        111, 111])\n",
      "tensor([126, 126, 141, 141,  38,  38, 135, 135, 118, 118, 158, 158,  78,  78,\n",
      "        123, 123])\n",
      "tensor([ 31,  31, 108, 108,  18,  18,  58,  58,   2,   2,  90,  90,  84,  84,\n",
      "         75,  75])\n",
      "tensor([ 30,  30, 148, 148, 105, 105, 144, 144,  18,  18, 163, 163,  89,  89,\n",
      "        124, 124])\n",
      "tensor([135, 135,  98,  98,  15,  15, 147, 147, 163, 163,  58,  58, 172, 172,\n",
      "         55,  55])\n",
      "tensor([138, 138, 172, 172, 151, 151,  75,  75,  30,  30,  44,  44,  22,  22,\n",
      "         33,  33])\n",
      "tensor([147, 147,  58,  58,  72,  72,   8,   8, 106, 106,  78,  78,  22,  22,\n",
      "         60,  60])\n",
      "tensor([ 25,  25,  14,  14,  25,  25,  11,  11,   8,   8, 154, 154, 145, 145,\n",
      "        156, 156])\n",
      "tensor([167, 167,  48,  48, 145, 145,  21,  21,  77,  77, 132, 132,   1,   1,\n",
      "        139, 139])\n",
      "tensor([104, 104,  57,  57, 142, 142, 166, 166, 143, 143, 108, 108, 148, 148,\n",
      "         77,  77])\n",
      "tensor([ 30,  30,  24,  24,  15,  15, 122, 122,  61,  61,  48,  48, 118, 118,\n",
      "        163, 163])\n",
      "tensor([ 90,  90, 147, 147,  96,  96,  46,  46,  39,  39,  81,  81,  58,  58,\n",
      "          1,   1])\n",
      "tensor([ 21,  21, 106, 106, 146, 146, 142, 142, 138, 138,  48,  48, 132, 132,\n",
      "         10,  10])\n",
      "tensor([147, 147,  32,  32,  52,  52, 129, 129, 144, 144, 171, 171, 107, 107,\n",
      "         30,  30])\n",
      "tensor([134, 134, 117, 117, 147, 147, 152, 152, 119, 119,  86,  86,  92,  92,\n",
      "          3,   3])\n",
      "tensor([123, 123,  47,  47, 149, 149, 151, 151,  15,  15, 118, 118, 120, 120,\n",
      "         88,  88])\n",
      "tensor([ 61,  61, 117, 117, 111, 111,  66,  66, 169, 169, 100, 100,  63,  63,\n",
      "         96,  96])\n",
      "tensor([146, 146,   0,   0, 140, 140, 115, 115,   3,   3,  57,  57,  85,  85,\n",
      "          3,   3])\n",
      "tensor([  2,   2, 137, 137,   1,   1, 118, 118,   3,   3,  50,  50, 151, 151,\n",
      "         65,  65])\n",
      "tensor([ 11,  11, 128, 128,  13,  13, 107, 107, 109, 109, 128, 128,  48,  48,\n",
      "        162, 162])\n",
      "tensor([109, 109,  44,  44,  90,  90, 173, 173, 104, 104, 104, 104,  67,  67,\n",
      "        156, 156])\n",
      "tensor([131, 131,   5,   5,  95,  95, 170, 170,  76,  76, 100, 100,  88,  88,\n",
      "        101, 101])\n",
      "tensor([150, 150,  42,  42,  18,  18, 146, 146,  12,  12, 172, 172, 120, 120,\n",
      "        103, 103])\n",
      "tensor([131, 131, 166, 166, 167, 167, 166, 166,  69,  69,  97,  97,  44,  44,\n",
      "         96,  96])\n",
      "tensor([ 37,  37, 114, 114,  66,  66,  54,  54, 144, 144,  41,  41,  95,  95,\n",
      "        158, 158])\n",
      "tensor([ 16,  16,  64,  64, 163, 163, 118, 118, 167, 167,  38,  38, 148, 148,\n",
      "         46,  46])\n",
      "tensor([ 67,  67, 169, 169,  76,  76, 131, 131, 166, 166, 170, 170, 171, 171,\n",
      "         60,  60])\n",
      "tensor([141, 141, 172, 172, 133, 133,  11,  11,  27,  27, 141, 141,  55,  55,\n",
      "        145, 145])\n",
      "tensor([173, 173,  79,  79,  42,  42, 118, 118,  57,  57,  31,  31,  35,  35,\n",
      "         84,  84])\n",
      "tensor([ 56,  56,  52,  52,  57,  57, 101, 101,  68,  68, 132, 132,  79,  79,\n",
      "         37,  37])\n",
      "tensor([ 56,  56, 134, 134,  42,  42,  10,  10, 127, 127, 166, 166, 120, 120,\n",
      "         58,  58])\n",
      "tensor([104, 104,  55,  55, 128, 128,  50,  50, 134, 134,  54,  54, 154, 154,\n",
      "         18,  18])\n",
      "tensor([110, 110, 162, 162,  87,  87, 167, 167,  89,  89, 113, 113, 165, 165,\n",
      "        109, 109])\n",
      "tensor([ 76,  76, 118, 118, 116, 116, 148, 148, 156, 156,  76,  76, 109, 109,\n",
      "        172, 172])\n",
      "tensor([102, 102, 126, 126,  61,  61,  80,  80,  82,  82, 110, 110,  19,  19,\n",
      "         11,  11])\n",
      "tensor([141, 141,  68,  68,  82,  82,  65,  65,  68,  68,  88,  88, 100, 100,\n",
      "        132, 132])\n",
      "tensor([123, 123, 161, 161,  49,  49,  43,  43,  43,  43,  44,  44,  51,  51,\n",
      "        158, 158])\n",
      "tensor([151, 151, 101, 101,  71,  71,  88,  88,  26,  26,  36,  36,  72,  72,\n",
      "        153, 153])\n",
      "tensor([ 69,  69,  71,  71,  38,  38,  82,  82,  85,  85,  57,  57, 148, 148,\n",
      "        143, 143])\n",
      "tensor([ 72,  72,  75,  75,  91,  91, 121, 121,  35,  35,  19,  19,  51,  51,\n",
      "        154, 154])\n",
      "tensor([ 81,  81,  51,  51,  60,  60,  33,  33, 134, 134, 131, 131, 146, 146,\n",
      "        124, 124])\n",
      "tensor([ 75,  75,  49,  49, 103, 103,  14,  14, 102, 102,  66,  66,  87,  87,\n",
      "        140, 140])\n",
      "tensor([153, 153, 140, 140,  56,  56,  68,  68, 116, 116, 157, 157,  28,  28,\n",
      "        132, 132])\n",
      "tensor([139, 139,  59,  59,  11,  11,  89,  89,  62,  62, 172, 172, 125, 125,\n",
      "         60,  60])\n",
      "tensor([138, 138, 138, 138,  31,  31,  53,  53, 130, 130,   8,   8,  97,  97,\n",
      "        104, 104])\n",
      "tensor([ 88,  88, 145, 145,  56,  56, 120, 120,  42,  42, 161, 161,  10,  10,\n",
      "         40,  40])\n",
      "tensor([ 27,  27,  43,  43, 145, 145, 107, 107, 132, 132,  29,  29,  29,  29,\n",
      "         40,  40])\n",
      "tensor([102, 102,  64,  64, 131, 131, 113, 113, 132, 132, 101, 101, 137, 137,\n",
      "        172, 172])\n",
      "tensor([ 50,  50,  29,  29, 114, 114,   2,   2, 143, 143, 113, 113,  26,  26,\n",
      "        117, 117])\n",
      "tensor([ 89,  89,  18,  18, 142, 142,  91,  91,  47,  47, 134, 134, 110, 110,\n",
      "        155, 155])\n",
      "tensor([135, 135,  85,  85,   3,   3, 138, 138, 153, 153,  37,  37, 124, 124,\n",
      "          3,   3])\n",
      "tensor([ 98,  98,  38,  38, 100, 100, 150, 150, 144, 144,  17,  17, 137, 137,\n",
      "         31,  31])\n",
      "tensor([116, 116,  93,  93, 130, 130, 121, 121,  35,  35,  83,  83, 166, 166,\n",
      "         63,  63])\n",
      "tensor([170, 170,  85,  85,  11,  11,  54,  54,  44,  44,  20,  20,  70,  70,\n",
      "        122, 122])\n",
      "tensor([ 11,  11,  39,  39,  91,  91, 120, 120,   8,   8,  65,  65,  78,  78,\n",
      "        162, 162])\n",
      "tensor([115, 115,  24,  24,  85,  85,  71,  71, 136, 136,  80,  80,  68,  68,\n",
      "         49,  49])\n",
      "tensor([ 51,  51, 126, 126,  27,  27, 171, 171, 117, 117,  47,  47,  17,  17,\n",
      "         11,  11])\n",
      "tensor([165, 165, 134, 134,  96,  96, 172, 172,   1,   1, 105, 105,  18,  18,\n",
      "         90,  90])\n",
      "tensor([ 51,  51, 105, 105,  56,  56, 127, 127,  83,  83,  97,  97, 168, 168,\n",
      "         77,  77])\n",
      "tensor([ 84,  84, 108, 108, 168, 168, 108, 108,  47,  47,   2,   2,  91,  91,\n",
      "        102, 102])\n",
      "tensor([  2,   2,  34,  34, 113, 113, 120, 120,   7,   7,  11,  11,  74,  74,\n",
      "        126, 126])\n",
      "tensor([166, 166, 118, 118, 111, 111, 127, 127, 143, 143, 124, 124, 155, 155,\n",
      "         86,  86])\n",
      "tensor([  5,   5,  46,  46, 103, 103, 117, 117, 132, 132,  77,  77, 137, 137,\n",
      "         36,  36])\n",
      "tensor([ 65,  65,  72,  72,  26,  26,  18,  18, 114, 114,  14,  14, 126, 126,\n",
      "         90,  90])\n",
      "tensor([ 40,  40, 131, 131,  16,  16, 167, 167,  78,  78,  54,  54, 111, 111,\n",
      "        133, 133])\n",
      "tensor([ 25,  25, 157, 157,  94,  94,  51,  51,   7,   7,  47,  47,  64,  64,\n",
      "        173, 173])\n",
      "tensor([ 20,  20,  96,  96,  55,  55,  22,  22,  51,  51,  35,  35, 169, 169,\n",
      "         30,  30])\n",
      "tensor([ 32,  32,  73,  73,  57,  57, 172, 172,  21,  21, 113, 113,  23,  23,\n",
      "         67,  67])\n",
      "tensor([ 38,  38, 153, 153,  85,  85,  18,  18,  86,  86,  97,  97,  36,  36,\n",
      "         77,  77])\n",
      "tensor([122, 122, 153, 153,  31,  31, 129, 129, 101, 101,  45,  45,  87,  87,\n",
      "        132, 132])\n",
      "tensor([ 94,  94, 127, 127,   4,   4, 162, 162, 121, 121,  11,  11,  67,  67,\n",
      "        110, 110])\n",
      "tensor([100, 100, 162, 162, 144, 144, 116, 116,  42,  42,  75,  75, 112, 112,\n",
      "        119, 119])\n",
      "tensor([ 87,  87,  39,  39,  72,  72,  69,  69, 111, 111, 113, 113, 119, 119,\n",
      "         59,  59])\n",
      "tensor([ 86,  86, 119, 119,  38,  38, 122, 122, 119, 119,  95,  95,  60,  60,\n",
      "         30,  30])\n",
      "tensor([ 18,  18,   4,   4, 156, 156, 132, 132, 108, 108,  86,  86, 168, 168,\n",
      "         86,  86])\n",
      "tensor([ 46,  46,  94,  94, 145, 145, 169, 169, 137, 137,  97,  97,  31,  31,\n",
      "        164, 164])\n",
      "tensor([154, 154,  76,  76,   2,   2,  95,  95, 150, 150,  61,  61,  77,  77,\n",
      "         55,  55])\n",
      "tensor([  4,   4, 132, 132, 149, 149, 150, 150,  71,  71, 120, 120,  87,  87,\n",
      "         78,  78])\n",
      "tensor([136, 136, 140, 140,  37,  37,  52,  52,  48,  48, 159, 159, 149, 149,\n",
      "        124, 124])\n",
      "tensor([ 63,  63, 126, 126, 134, 134, 157, 157, 122, 122, 160, 160,  55,  55,\n",
      "         83,  83])\n",
      "tensor([ 41,  41,  28,  28, 134, 134, 169, 169, 125, 125,  41,  41,  98,  98,\n",
      "         88,  88])\n",
      "tensor([142, 142, 119, 119, 104, 104, 142, 142, 134, 134, 129, 129,  67,  67,\n",
      "         39,  39])\n",
      "tensor([  1,   1,  44,  44, 115, 115, 154, 154, 107, 107,  18,  18,  69,  69,\n",
      "         35,  35])\n",
      "tensor([ 46,  46,  66,  66,  93,  93,  31,  31, 107, 107,  90,  90,  44,  44,\n",
      "         43,  43])\n",
      "tensor([151, 151, 137, 137,  85,  85, 101, 101,  99,  99, 163, 163, 165, 165,\n",
      "        102, 102])\n",
      "tensor([162, 162,  38,  38, 117, 117,  55,  55,  34,  34, 118, 118,  10,  10,\n",
      "         83,  83])\n",
      "tensor([ 82,  82, 115, 115, 138, 138,  87,  87,  40,  40, 118, 118, 125, 125,\n",
      "        134, 134])\n",
      "tensor([142, 142, 108, 108,  62,  62, 126, 126,  35,  35,  69,  69, 163, 163,\n",
      "        123, 123])\n",
      "tensor([ 82,  82, 122, 122,  56,  56, 132, 132, 104, 104,  52,  52,  31,  31,\n",
      "        168, 168])\n",
      "tensor([ 60,  60,  46,  46,  32,  32, 123, 123, 121, 121, 159, 159, 127, 127,\n",
      "         77,  77])\n",
      "tensor([107, 107,   5,   5,  78,  78, 118, 118, 155, 155,  10,  10,   9,   9,\n",
      "        135, 135])\n",
      "tensor([ 77,  77,  45,  45, 128, 128,  38,  38,  37,  37,  89,  89, 100, 100,\n",
      "        156, 156])\n",
      "tensor([ 90,  90, 114, 114,   0,   0, 112, 112,   7,   7,  68,  68, 164, 164,\n",
      "         20,  20])\n",
      "tensor([154, 154,  27,  27, 154, 154, 144, 144,  23,  23,  47,  47, 150, 150,\n",
      "         63,  63])\n",
      "tensor([ 59,  59,  59,  59,  34,  34,  18,  18, 171, 171, 115, 115, 152, 152,\n",
      "        114, 114])\n",
      "tensor([149, 149, 108, 108,  13,  13,  26,  26,  11,  11,  91,  91, 155, 155,\n",
      "        152, 152])\n",
      "tensor([117, 117,  63,  63,  50,  50, 135, 135,   5,   5,  90,  90, 169, 169,\n",
      "         77,  77])\n",
      "tensor([164, 164, 153, 153,   1,   1, 123, 123,  93,  93,  28,  28,  48,  48,\n",
      "         60,  60])\n",
      "tensor([128, 128,  90,  90,  26,  26,  11,  11, 148, 148,  27,  27,  36,  36,\n",
      "        136, 136])\n",
      "tensor([144, 144,  71,  71,  25,  25,  45,  45, 155, 155, 172, 172, 145, 145,\n",
      "        121, 121])\n",
      "tensor([ 42,  42,  35,  35, 114, 114,   2,   2, 145, 145,  53,  53, 109, 109,\n",
      "        132, 132])\n",
      "tensor([123, 123,  49,  49,   2,   2, 150, 150, 151, 151,  85,  85,  87,  87,\n",
      "        163, 163])\n",
      "tensor([ 71,  71,  70,  70, 161, 161, 139, 139,  94,  94, 152, 152, 133, 133,\n",
      "        169, 169])\n",
      "tensor([132, 132,   4,   4,  32,  32, 162, 162,  31,  31,  68,  68,  90,  90,\n",
      "         85,  85])\n",
      "tensor([169, 169,  70,  70,  29,  29,  59,  59, 127, 127,  76,  76,  63,  63,\n",
      "         33,  33])\n",
      "tensor([ 29,  29,  95,  95, 136, 136,  23,  23, 106, 106, 131, 131, 107, 107,\n",
      "          5,   5])\n",
      "tensor([161, 161,   1,   1,  97,  97, 134, 134,  88,  88,  71,  71, 160, 160,\n",
      "        105, 105])\n",
      "tensor([ 23,  23, 136, 136, 172, 172,  13,  13, 155, 155, 157, 157, 158, 158,\n",
      "         91,  91])\n",
      "tensor([101, 101,  20,  20, 155, 155,  31,  31, 151, 151,  22,  22, 151, 151,\n",
      "         41,  41])\n",
      "tensor([ 62,  62,  72,  72, 147, 147,  68,  68,   0,   0,  35,  35,  12,  12,\n",
      "         39,  39])\n",
      "tensor([ 45,  45, 152, 152,  18,  18,  63,  63,  89,  89,  59,  59, 145, 145,\n",
      "         13,  13])\n",
      "tensor([ 60,  60,  35,  35, 153, 153,  51,  51,  77,  77,  24,  24,  79,  79,\n",
      "         67,  67])\n",
      "tensor([105, 105,  79,  79,  96,  96,  54,  54,  42,  42,  50,  50,  72,  72,\n",
      "         51,  51])\n",
      "tensor([156, 156,  56,  56, 143, 143, 119, 119,  50,  50, 172, 172,  89,  89,\n",
      "         65,  65])\n",
      "tensor([ 66,  66, 127, 127, 121, 121, 123, 123, 120, 120, 127, 127,  76,  76,\n",
      "         88,  88])\n",
      "tensor([ 97,  97, 160, 160, 102, 102,   2,   2,  36,  36,   7,   7,  74,  74,\n",
      "         18,  18])\n",
      "tensor([155, 155,   5,   5, 103, 103,  48,  48, 117, 117, 149, 149,   3,   3,\n",
      "         90,  90])\n",
      "tensor([133, 133,  46,  46, 167, 167, 119, 119,  41,  41,  97,  97, 100, 100,\n",
      "         81,  81])\n",
      "tensor([159, 159,  38,  38,  33,  33,   4,   4, 109, 109, 119, 119,  95,  95,\n",
      "         87,  87])\n",
      "tensor([128, 128, 121, 121, 156, 156,  13,  13, 152, 152, 112, 112,  21,  21,\n",
      "        155, 155])\n",
      "tensor([ 88,  88,  70,  70, 122, 122, 144, 144, 143, 143,   3,   3,  62,  62,\n",
      "        173, 173])\n",
      "tensor([ 72,  72,  15,  15, 112, 112,  10,  10, 119, 119,  26,  26, 140, 140,\n",
      "        141, 141])\n",
      "tensor([ 79,  79,  13,  13, 110, 110,  14,  14, 170, 170,  11,  11, 148, 148,\n",
      "         67,  67])\n",
      "tensor([ 54,  54,   4,   4,  69,  69,  83,  83,  48,  48,   9,   9, 103, 103,\n",
      "         36,  36])\n",
      "tensor([ 24,  24,   5,   5, 128, 128, 122, 122,  58,  58, 101, 101, 144, 144,\n",
      "         17,  17])\n",
      "tensor([ 74,  74,  70,  70,  51,  51, 150, 150,  77,  77,  98,  98,  93,  93,\n",
      "         11,  11])\n",
      "tensor([  8,   8, 112, 112,  46,  46,   7,   7,  71,  71,  67,  67,  73,  73,\n",
      "         23,  23])\n",
      "tensor([ 59,  59, 150, 150, 109, 109,  66,  66,  17,  17, 159, 159,  91,  91,\n",
      "         73,  73])\n",
      "tensor([ 14,  14,  61,  61,  29,  29,  76,  76, 115, 115,  62,  62,  87,  87,\n",
      "        141, 141])\n",
      "tensor([129, 129, 145, 145,  36,  36, 126, 126,  92,  92,  90,  90, 132, 132,\n",
      "         28,  28])\n",
      "tensor([105, 105, 161, 161,  54,  54,  75,  75, 161, 161, 111, 111, 155, 155,\n",
      "         75,  75])\n",
      "tensor([ 75,  75,  32,  32,  73,  73,  44,  44,   4,   4, 106, 106, 155, 155,\n",
      "        104, 104])\n",
      "tensor([166, 166,  24,  24,  51,  51,  59,  59, 111, 111,  85,  85,  32,  32,\n",
      "        167, 167])\n",
      "tensor([ 33,  33,  68,  68, 121, 121,  43,  43, 157, 157, 116, 116, 158, 158,\n",
      "         88,  88])\n",
      "tensor([104, 104, 166, 166, 145, 145,  65,  65,  75,  75,  27,  27, 137, 137,\n",
      "        149, 149])\n",
      "tensor([ 61,  61, 103, 103,  97,  97,  88,  88,  80,  80,  44,  44,  32,  32,\n",
      "         23,  23])\n",
      "tensor([164, 164, 157, 157,  92,  92,  51,  51, 109, 109, 113, 113,   0,   0,\n",
      "        146, 146])\n",
      "tensor([  0,   0, 100, 100, 143, 143, 112, 112,  45,  45, 131, 131, 156, 156,\n",
      "        153, 153])\n",
      "tensor([143, 143,  22,  22, 112, 112,  28,  28, 137, 137, 103, 103, 100, 100,\n",
      "         33,  33])\n",
      "tensor([158, 158,  80,  80,  19,  19,  78,  78,  49,  49,  63,  63,  87,  87,\n",
      "        160, 160])\n",
      "tensor([ 20,  20,  33,  33,  17,  17,  29,  29, 116, 116,  61,  61, 155, 155,\n",
      "          8,   8])\n",
      "tensor([106, 106,   4,   4,  25,  25,   9,   9, 153, 153,  47,  47, 159, 159,\n",
      "        153, 153])\n",
      "tensor([121, 121, 132, 132, 102, 102, 171, 171,  84,  84,  86,  86,  33,  33,\n",
      "        154, 154])\n",
      "tensor([18, 18, 98, 98, 43, 43, 74, 74, 62, 62, 84, 84, 57, 57, 14, 14])\n",
      "tensor([ 57,  57, 139, 139, 169, 169,  22,  22, 140, 140, 103, 103,  82,  82,\n",
      "        124, 124])\n",
      "tensor([130, 130,  44,  44,  82,  82, 108, 108, 153, 153,  83,  83,  97,  97,\n",
      "         13,  13])\n",
      "tensor([  5,   5,  12,  12,  40,  40,  12,  12,  51,  51, 132, 132, 134, 134,\n",
      "        116, 116])\n",
      "tensor([127, 127, 108, 108, 165, 165,  49,  49, 156, 156,  46,  46, 122, 122,\n",
      "         37,  37])\n",
      "tensor([ 67,  67,  11,  11, 104, 104,  39,  39,  27,  27,  31,  31, 120, 120,\n",
      "        150, 150])\n",
      "tensor([ 12,  12,  34,  34,  14,  14,  64,  64, 126, 126, 132, 132, 105, 105,\n",
      "        133, 133])\n",
      "tensor([ 88,  88,  10,  10, 112, 112,  76,  76,  80,  80, 126, 126, 168, 168,\n",
      "         90,  90])\n",
      "tensor([  1,   1, 101, 101, 157, 157, 105, 105,  88,  88, 131, 131, 143, 143,\n",
      "        114, 114])\n",
      "tensor([ 38,  38, 116, 116, 155, 155,  59,  59,  13,  13, 136, 136, 145, 145,\n",
      "        140, 140])\n",
      "tensor([ 65,  65, 165, 165,  76,  76,  42,  42, 124, 124, 160, 160,  96,  96,\n",
      "         17,  17])\n",
      "tensor([ 86,  86,  40,  40, 130, 130,  30,  30,  25,  25,  94,  94, 147, 147,\n",
      "         95,  95])\n",
      "tensor([ 98,  98, 110, 110,  95,  95,  58,  58, 119, 119, 132, 132, 108, 108,\n",
      "         48,  48])\n",
      "tensor([147, 147,  91,  91,  55,  55, 172, 172, 159, 159, 132, 132,  80,  80,\n",
      "        141, 141])\n",
      "tensor([91, 91, 90, 90, 89, 89, 85, 85, 94, 94, 40, 40, 13, 13, 39, 39])\n",
      "tensor([103, 103, 149, 149, 145, 145, 143, 143,  45,  45,  30,  30, 150, 150,\n",
      "          5,   5])\n",
      "tensor([  9,   9, 162, 162,  40,  40,  16,  16,  70,  70, 128, 128,  91,  91,\n",
      "        107, 107])\n",
      "tensor([149, 149, 164, 164,   0,   0,  83,  83, 162, 162,  96,  96,  50,  50,\n",
      "        132, 132])\n",
      "tensor([160, 160, 144, 144,  54,  54,  52,  52, 163, 163,  99,  99, 135, 135,\n",
      "        142, 142])\n",
      "tensor([ 43,  43,  21,  21,  59,  59, 131, 131, 156, 156,  12,  12, 105, 105,\n",
      "         94,  94])\n",
      "tensor([ 93,  93,  14,  14,  46,  46,   2,   2,  49,  49, 113, 113,  60,  60,\n",
      "        151, 151])\n",
      "tensor([ 13,  13,  85,  85,  51,  51, 169, 169, 159, 159, 156, 156,  28,  28,\n",
      "        155, 155])\n",
      "tensor([ 62,  62, 127, 127,  82,  82,  61,  61,  91,  91,  64,  64, 142, 142,\n",
      "        101, 101])\n",
      "tensor([116, 116, 130, 130,  27,  27, 162, 162,  95,  95,  24,  24,  49,  49,\n",
      "         25,  25])\n",
      "tensor([ 58,  58,  69,  69,  91,  91, 139, 139,  47,  47,  59,  59, 116, 116,\n",
      "         58,  58])\n",
      "tensor([ 52,  52,  52,  52, 117, 117, 124, 124,  42,  42,  24,  24,  60,  60,\n",
      "         59,  59])\n",
      "tensor([ 43,  43,  42,  42,  75,  75,  27,  27,  50,  50,   2,   2, 136, 136,\n",
      "         18,  18])\n",
      "tensor([ 42,  42, 156, 156, 100, 100, 154, 154,  84,  84, 131, 131, 109, 109,\n",
      "          6,   6])\n",
      "tensor([ 62,  62, 146, 146,  39,  39,  99,  99, 100, 100,  57,  57,  70,  70,\n",
      "        132, 132])\n",
      "tensor([126, 126,   9,   9, 146, 146, 135, 135, 153, 153, 169, 169,  44,  44,\n",
      "        138, 138])\n",
      "tensor([118, 118, 141, 141,  34,  34,  55,  55, 154, 154,   3,   3,  95,  95,\n",
      "        107, 107])\n",
      "tensor([ 69,  69,  32,  32,  50,  50, 111, 111, 152, 152, 102, 102, 102, 102,\n",
      "         81,  81])\n",
      "tensor([157, 157,  37,  37, 168, 168,  30,  30,  85,  85,  11,  11, 171, 171,\n",
      "         42,  42])\n",
      "tensor([170, 170,  68,  68, 172, 172,  48,  48,  98,  98,  45,  45,  41,  41,\n",
      "        154, 154])\n",
      "tensor([ 97,  97,  59,  59,  57,  57,  75,  75,  64,  64,  84,  84,  13,  13,\n",
      "        142, 142])\n",
      "tensor([39, 39, 23, 23, 39, 39, 48, 48, 75, 75,  2,  2, 13, 13, 90, 90])\n",
      "tensor([159, 159, 167, 167, 160, 160,  57,  57,  85,  85,  63,  63, 102, 102,\n",
      "         79,  79])\n"
     ]
    }
   ],
   "source": [
    "for batch in dataloader_train:\n",
    "    print(batch.lab)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "511ffcec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({99: 9, 28: 8, 52: 8, 91: 8, 92: 8, 122: 8, 123: 8, 129: 8, 169: 8, 2: 7, 4: 7, 6: 7, 8: 7, 19: 7, 20: 7, 30: 7, 33: 7, 36: 7, 37: 7, 39: 7, 42: 7, 46: 7, 47: 7, 48: 7, 56: 7, 61: 7, 62: 7, 65: 7, 67: 7, 74: 7, 76: 7, 77: 7, 79: 7, 85: 7, 86: 7, 87: 7, 88: 7, 90: 7, 93: 7, 95: 7, 96: 7, 104: 7, 105: 7, 107: 7, 109: 7, 113: 7, 114: 7, 115: 7, 119: 7, 120: 7, 121: 7, 126: 7, 130: 7, 133: 7, 134: 7, 136: 7, 137: 7, 138: 7, 148: 7, 151: 7, 155: 7, 156: 7, 159: 7, 162: 7, 164: 7, 166: 7, 167: 7, 173: 7, 0: 6, 1: 6, 3: 6, 5: 6, 7: 6, 9: 6, 11: 6, 13: 6, 14: 6, 16: 6, 18: 6, 22: 6, 23: 6, 25: 6, 27: 6, 31: 6, 32: 6, 34: 6, 35: 6, 38: 6, 40: 6, 43: 6, 44: 6, 45: 6, 50: 6, 51: 6, 53: 6, 55: 6, 58: 6, 59: 6, 60: 6, 63: 6, 64: 6, 66: 6, 68: 6, 70: 6, 71: 6, 72: 6, 73: 6, 75: 6, 78: 6, 80: 6, 81: 6, 82: 6, 83: 6, 84: 6, 94: 6, 102: 6, 103: 6, 106: 6, 108: 6, 110: 6, 111: 6, 116: 6, 117: 6, 124: 6, 125: 6, 127: 6, 128: 6, 131: 6, 132: 6, 135: 6, 140: 6, 141: 6, 142: 6, 143: 6, 144: 6, 145: 6, 146: 6, 147: 6, 149: 6, 150: 6, 152: 6, 153: 6, 154: 6, 158: 6, 160: 6, 161: 6, 163: 6, 165: 6, 168: 6, 170: 6, 10: 5, 12: 5, 15: 5, 17: 5, 21: 5, 24: 5, 26: 5, 29: 5, 41: 5, 49: 5, 54: 5, 57: 5, 69: 5, 89: 5, 97: 5, 98: 5, 100: 5, 101: 5, 112: 5, 118: 5, 139: 5, 157: 5, 171: 5, 172: 5})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# Assuming your labels are stored in a list called 'labels'\n",
    "labels = [item['lab'] for item in dataset_train]\n",
    "\n",
    "# Count the occurrences of each label\n",
    "label_distribution = Counter(labels)\n",
    "\n",
    "# Print the label distribution\n",
    "print(label_distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7c0db5d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique labels in the training set: 174\n",
      "Unique labels in the validation set: {0, 1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 22, 23, 26, 28, 29, 30, 31, 32, 33, 34, 36, 37, 38, 39, 40, 42, 43, 44, 45, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 61, 64, 65, 66, 67, 68, 70, 71, 72, 73, 74, 75, 77, 78, 79, 80, 81, 83, 84, 85, 86, 87, 88, 91, 93, 95, 96, 99, 101, 103, 105, 106, 107, 108, 111, 112, 113, 114, 115, 117, 118, 119, 120, 121, 122, 123, 124, 126, 127, 129, 130, 131, 133, 134, 135, 136, 137, 138, 143, 144, 145, 146, 148, 149, 150, 151, 152, 153, 155, 158, 160, 161, 162, 163, 164, 166, 167, 168, 169, 170, 172, 173}\n"
     ]
    }
   ],
   "source": [
    "train_labels = [item['lab'] for item in train_data]\n",
    "\n",
    "# Extract labels from val_data\n",
    "val_labels = [item['lab'] for item in val_data]\n",
    "\n",
    "# Get unique labels in train and validation sets\n",
    "unique_train_labels = set(train_labels)\n",
    "unique_val_labels = set(val_labels)\n",
    "\n",
    "print(\"Unique labels in the training set:\", len(unique_train_labels))\n",
    "print(\"Unique labels in the validation set:\", unique_val_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f9d95912",
   "metadata": {},
   "outputs": [],
   "source": [
    "from speechbrain.inference.speaker import SpeakerRecognition\n",
    "import torchaudio\n",
    "verification = SpeakerRecognition.from_hparams(source=\"speechbrain/spkrec-resnet-voxceleb\", savedir=\"pretrained_models/spkrec-resnet-voxceleb\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "16b19564",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(1, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (activation1): ReLU()\n",
       "  (layer1): Sequential(\n",
       "    (0): SEBasicBlock(\n",
       "      (activation): ReLU()\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (se): SEBlock(\n",
       "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): SEBasicBlock(\n",
       "      (activation): ReLU()\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (se): SEBlock(\n",
       "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (2): SEBasicBlock(\n",
       "      (activation): ReLU()\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (se): SEBlock(\n",
       "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): SEBasicBlock(\n",
       "      (activation): ReLU()\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (se): SEBlock(\n",
       "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): SEBasicBlock(\n",
       "      (activation): ReLU()\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (se): SEBlock(\n",
       "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (2): SEBasicBlock(\n",
       "      (activation): ReLU()\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (se): SEBlock(\n",
       "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (3): SEBasicBlock(\n",
       "      (activation): ReLU()\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (se): SEBlock(\n",
       "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (activation): ReLU()\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (activation): ReLU()\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (activation): ReLU()\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    )\n",
       "    (3): BasicBlock(\n",
       "      (activation): ReLU()\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    )\n",
       "    (4): BasicBlock(\n",
       "      (activation): ReLU()\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    )\n",
       "    (5): BasicBlock(\n",
       "      (activation): ReLU()\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (activation): ReLU()\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (activation): ReLU()\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (activation): ReLU()\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    )\n",
       "  )\n",
       "  (norm_stats): BatchNorm1d(5120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (attention): Sequential(\n",
       "    (0): Conv1d(2560, 128, kernel_size=(1,), stride=(1,))\n",
       "    (1): ReLU()\n",
       "    (2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): Conv1d(128, 2560, kernel_size=(1,), stride=(1,))\n",
       "    (4): Softmax(dim=2)\n",
       "  )\n",
       "  (fc_embed): Linear(in_features=5120, out_features=256, bias=True)\n",
       "  (norm_embed): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       ")"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from speechbrain.lobes.models.ResNet import ResNet\n",
    "from speechbrain.utils.parameter_transfer import Pretrainer\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = ResNet(input_size=80, \n",
    "               device=device, \n",
    "               channels=[128, 128, 256, 256], \n",
    "               block_sizes=[3, 4, 6, 3], \n",
    "               strides=[1, 2, 2, 2], \n",
    "               lin_neurons=256)\n",
    "\n",
    "pretrainer = speechbrain.utils.parameter_transfer.Pretrainer(loadables={'model': model}, paths={'model': 'speechbrain/spkrec-resnet-voxceleb/embedding_model.ckpt'})\n",
    "pretrainer.collect_files\n",
    "pretrainer.load_collected()\n",
    "\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e5b5f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b768b29d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "028429f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "class AdMSoftmaxLoss(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, in_features, out_features, s=30.0, m=0.4):\n",
    "        '''\n",
    "        AM Softmax Loss\n",
    "        '''\n",
    "        super(AdMSoftmaxLoss, self).__init__()\n",
    "        self.s = s\n",
    "        self.m = m\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.fc = nn.Linear(in_features, out_features, bias=False)\n",
    "\n",
    "    def forward(self, x, labels):\n",
    "        '''\n",
    "        input shape (N, in_features)\n",
    "        '''\n",
    "        assert len(x) == len(labels)\n",
    "        assert torch.min(labels) >= 0\n",
    "        assert torch.max(labels) < self.out_features\n",
    "        \n",
    "        for W in self.fc.parameters():\n",
    "            W = F.normalize(W, dim=1)\n",
    "\n",
    "        x = F.normalize(x, dim=1)\n",
    "\n",
    "        wf = self.fc(x)\n",
    "        numerator = self.s * (torch.diagonal(wf.transpose(0, 1)[labels]) - self.m)\n",
    "        excl = torch.cat([torch.cat((wf[i, :y], wf[i, y+1:])).unsqueeze(0) for i, y in enumerate(labels)], dim=0)\n",
    "        denominator = torch.exp(numerator) + torch.sum(torch.exp(self.s * excl), dim=1)\n",
    "        L = numerator - torch.log(denominator)\n",
    "        return -torch.mean(L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9fd5519e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'AdMSoftmaxLoss' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 11\u001b[0m\n\u001b[1;32m      9\u001b[0m in_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m256\u001b[39m  \u001b[38;5;66;03m# This should match the output size of the last layer of the model\u001b[39;00m\n\u001b[1;32m     10\u001b[0m out_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m   \u001b[38;5;66;03m# Number of classes (binary classification)\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m criterion \u001b[38;5;241m=\u001b[39m \u001b[43mAdMSoftmaxLoss\u001b[49m(in_features, out_features, s\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m30.0\u001b[39m, m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.4\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Define the loss function and optimizer\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# loss_fn = AdditiveAngularMargin()\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     23\u001b[0m \n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# Initialize the optimizer with parameter groups\u001b[39;00m\n\u001b[1;32m     25\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdam(criterion\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.01\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'AdMSoftmaxLoss' is not defined"
     ]
    }
   ],
   "source": [
    "from speechbrain.nnet.losses import AdditiveAngularMargin\n",
    "from speechbrain.utils.metric_stats import EER\n",
    "from speechbrain.utils.distributed import run_on_main\n",
    "from speechbrain.utils.checkpoints import Checkpointer\n",
    "from speechbrain.utils import epoch_loop\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "in_features = 256  # This should match the output size of the last layer of the model\n",
    "out_features = 2   # Number of classes (binary classification)\n",
    "criterion = AdMSoftmaxLoss(in_features, out_features, s=30.0, m=0.4).to(device)\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "# loss_fn = AdditiveAngularMargin()\n",
    "\n",
    "# pretrained_params = list(model.layer2.parameters()) + list(model.layer3.parameters()) + list(model.layer4.parameters())\n",
    "# new_params = list(model.fc_embed.parameters())\n",
    "\n",
    "# param_groups = [\n",
    "#     {'params': pretrained_params, 'lr': 0.005},\n",
    "#     {'params': new_params, 'lr': 0.001}\n",
    "# ]\n",
    "\n",
    "# Initialize the optimizer with parameter groups\n",
    "optimizer = torch.optim.Adam(criterion.parameters(), lr=0.01)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=30, eta_min=0.001)\n",
    "\n",
    "\n",
    "# Initialize the checkpointer\n",
    "checkpointer = Checkpointer(checkpoints_dir=\"checkpoint_dir\", recoverables={'model': model, 'optimizer': optimizer})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "af41304c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def nt_bxent_loss(x, pos_indices, temperature):\n",
    "    assert len(x.size()) == 2\n",
    "\n",
    "    # Add indexes of the principal diagonal elements to pos_indices\n",
    "    pos_indices = torch.cat([\n",
    "        pos_indices,\n",
    "        torch.arange(x.size(0)).reshape(x.size(0), 1).expand(-1, 2).to(x.device),\n",
    "    ], dim=0)\n",
    "\n",
    "    # Ground truth labels\n",
    "    target = torch.zeros(x.size(0), x.size(0), device=x.device)\n",
    "    target[pos_indices[:,0], pos_indices[:,1]] = 1.0\n",
    "\n",
    "    # Cosine similarity\n",
    "    xcs = F.cosine_similarity(x[None,:,:], x[:,None,:], dim=-1)\n",
    "    # Set logit of diagonal element to \"inf\" signifying complete\n",
    "    # correlation. sigmoid(inf) = 1.0 so this will work out nicely\n",
    "    # when computing the Binary Cross Entropy Loss.\n",
    "    xcs[torch.eye(x.size(0), device=x.device).bool()] = float(\"inf\")\n",
    "\n",
    "    # Standard binary cross entropy loss\n",
    "    loss = F.binary_cross_entropy((xcs / temperature).sigmoid(), target, reduction=\"none\")\n",
    "\n",
    "    target_pos = target.bool()\n",
    "    target_neg = ~target_pos\n",
    "\n",
    "    loss_pos = torch.zeros(x.size(0), x.size(0), device=x.device).masked_scatter(target_pos, loss[target_pos])\n",
    "    loss_neg = torch.zeros(x.size(0), x.size(0), device=x.device).masked_scatter(target_neg, loss[target_neg])\n",
    "    loss_pos = loss_pos.sum(dim=1)\n",
    "    loss_neg = loss_neg.sum(dim=1)\n",
    "    num_pos = target.sum(dim=1)\n",
    "    num_neg = x.size(0) - num_pos\n",
    "\n",
    "    return ((loss_pos / num_pos) + (loss_neg / num_neg)).mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6750ce92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class NTXentLoss(nn.Module):\n",
    "    def __init__(self, temperature=0.5):\n",
    "        super(NTXentLoss, self).__init__()\n",
    "        self.temperature = temperature\n",
    "\n",
    "    def forward(self, z_i, z_j):\n",
    "        batch_size = z_i.size(0)\n",
    "\n",
    "        # Ensure the inputs are float tensors\n",
    "        z_i = z_i.float()\n",
    "        z_j = z_j.float()\n",
    "\n",
    "        z_i = F.normalize(z_i, dim=1)\n",
    "        z_j = F.normalize(z_j, dim=1)\n",
    "\n",
    "        representations = torch.cat([z_i, z_j], dim=0)\n",
    "        similarity_matrix = F.cosine_similarity(representations.unsqueeze(1), representations.unsqueeze(0), dim=2)\n",
    "\n",
    "        sim_ij = torch.diag(similarity_matrix, batch_size)\n",
    "        sim_ji = torch.diag(similarity_matrix, -batch_size)\n",
    "\n",
    "        positive_samples = torch.cat([sim_ij, sim_ji], dim=0)\n",
    "        positive_samples = positive_samples / self.temperature\n",
    "\n",
    "        negative_samples = similarity_matrix / self.temperature\n",
    "\n",
    "        labels = torch.arange(2 * batch_size).to(z_i.device)\n",
    "        loss = F.cross_entropy(negative_samples, labels)\n",
    "\n",
    "        return loss.mean()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f3289e4",
   "metadata": {},
   "source": [
    "## softmax layer training ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8bc60500",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch-local/ivbeveren.6569262/ipykernel_880169/3766782426.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  labels = torch.tensor(labels, dtype=torch.long).to(device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30, Loss: 9.323351860046387\n",
      "Epoch 2/30, Loss: 8.885387420654297\n",
      "Epoch 3/30, Loss: 8.829681396484375\n",
      "Epoch 4/30, Loss: 8.967159271240234\n",
      "Epoch 5/30, Loss: 9.028463363647461\n",
      "Epoch 6/30, Loss: 9.044422149658203\n",
      "Epoch 7/30, Loss: 9.056853294372559\n",
      "Epoch 8/30, Loss: 9.045794486999512\n",
      "Epoch 9/30, Loss: 9.01041030883789\n",
      "Epoch 10/30, Loss: 8.958152770996094\n",
      "Epoch 11/30, Loss: 8.894526481628418\n",
      "Epoch 12/30, Loss: 8.825304985046387\n",
      "Epoch 13/30, Loss: 8.755851745605469\n",
      "Epoch 14/30, Loss: 8.690963745117188\n",
      "Epoch 15/30, Loss: 8.634889602661133\n",
      "Epoch 16/30, Loss: 8.590059280395508\n",
      "Epoch 17/30, Loss: 8.557659149169922\n",
      "Epoch 18/30, Loss: 8.538214683532715\n",
      "Epoch 19/30, Loss: 8.531195640563965\n",
      "Epoch 20/30, Loss: 8.535123825073242\n",
      "Epoch 21/30, Loss: 8.548553466796875\n",
      "Epoch 22/30, Loss: 8.571151733398438\n",
      "Epoch 23/30, Loss: 8.603395462036133\n",
      "Epoch 24/30, Loss: 8.644685745239258\n",
      "Epoch 25/30, Loss: 8.691736221313477\n",
      "Epoch 26/30, Loss: 8.738676071166992\n",
      "Epoch 27/30, Loss: 8.778890609741211\n",
      "Epoch 28/30, Loss: 8.807186126708984\n",
      "Epoch 29/30, Loss: 8.820680618286133\n",
      "Epoch 30/30, Loss: 8.818185806274414\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 30\n",
    "for epoch in range(num_epochs):\n",
    "    model.eval()  # Pre-trained layers are frozen, so no need for dropout or batchnorm in training mode\n",
    "    # criterion.train()\n",
    "    for batch in dataloader_train:\n",
    "        signal1, signal2, labels = batch[\"signal1\"], batch[\"signal2\"], batch[\"lab\"]\n",
    "        \n",
    "        signal1 = signal1.data.to(device)\n",
    "        signal2 = signal2.data.to(device)\n",
    "        labels = torch.tensor(labels, dtype=torch.long).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            embeddings1 = model(signal1)\n",
    "            embeddings2 = model(signal2)\n",
    "                        \n",
    "        # Create the one-hot encoded targets\n",
    "#         targets = F.one_hot(labels, num_classes=2).float().to(device)\n",
    "        \n",
    "        \n",
    "        embeddings = torch.cat((embeddings1, embeddings2), dim=0)\n",
    "        # AM softmax loss\n",
    "        labels = torch.cat((labels, labels), dim=0)\n",
    "        loss = criterion(embeddings, labels)\n",
    "        \n",
    "        # AAM softmax loss\n",
    "        cosine_sim = F.cosine_similarity(embeddings1, embeddings2)\n",
    "\n",
    "        # Apply the AAM loss function\n",
    "        loss = loss_fn(cosine_sim, targets)      \n",
    "        loss = abs(loss.mean())\n",
    "\n",
    "          # NT-Xent loss\n",
    "#         batch_size = signal1.size(0)\n",
    "#         pos_indices = torch.arange(batch_size).unsqueeze(1).repeat(1, 2)\n",
    "        \n",
    "#         Apply the NT-Xent loss function\n",
    "#         loss = nt_bxent_loss(embeddings.to(device), pos_indices.to(device), temperature=0.5)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "#         print(\"did a train loop\")\n",
    "\n",
    "    scheduler.step()\n",
    "    checkpointer.save_and_keep_only(meta={\"loss\": loss.item()}, num_to_keep=1)\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {loss.item()}\")\n",
    "\n",
    "# Save the final model\n",
    "torch.save(model.state_dict(), \"fine_tuned_model.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8db9c6db",
   "metadata": {},
   "source": [
    "## Full nn training ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "7784d922",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for param in model.parameters():\n",
    "#     param.requires_grad = True\n",
    "from speechbrain.nnet.losses import AdditiveAngularMargin\n",
    "from speechbrain.utils.metric_stats import EER\n",
    "from speechbrain.utils.distributed import run_on_main\n",
    "from speechbrain.utils.checkpoints import Checkpointer\n",
    "from speechbrain.utils import epoch_loop\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from speechbrain.nnet.losses import LogSoftmaxWrapper, AdditiveAngularMargin\n",
    "from speechbrain.lobes.models.ResNet import Classifier\n",
    "\n",
    "\n",
    "# for param in model.conv1.parameters():\n",
    "#     param.requires_grad = False\n",
    "# for param in model.layer1.parameters():\n",
    "#     param.requires_grad = False\n",
    "# Define parameter groups with different learning rates\n",
    "# model.fc_embed = torch.nn.Linear(in_features=5120, out_features=256, bias=True, device=device)\n",
    "# for param in model.fc_embed.parameters():\n",
    "#     param.requires_grad = True\n",
    "\n",
    "pretrained_params = list(model.layer1.parameters()) + list(model.layer2.parameters()) + list(model.layer3.parameters()) + list(model.layer4.parameters())\n",
    "new_params = list(model.fc_embed.parameters())\n",
    "criterion = losses.NTXentLoss(temperature=0.07)\n",
    "param_groups = [\n",
    "    {'params': pretrained_params, 'lr': 0.005},\n",
    "    {'params': new_params, 'lr': 0.001},\n",
    "    # {'params': list(criterion.parameters()), 'lr':0.001}   \n",
    "]\n",
    "\n",
    "# Re-initialize the optimizer with parameter groups\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "# scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=30, eta_min=0.001)\n",
    "checkpointer = Checkpointer(checkpoints_dir=\"checkpoint_dir\", recoverables={'model': model, 'optimizer': optimizer})\n",
    "clas = Classifier(input_size = 256, out_neurons = 174).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "462f421f-6cd1-4aea-bea1-faa1bdbfe359",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 1, 174])\n",
      "torch.Size([8, 1])\n",
      "tensor(13.0202, grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "for batch in dataloader_train:\n",
    "    signal1, labels = batch[\"signal1\"], batch[\"lab\"]\n",
    "    labels = torch.LongTensor(labels).unsqueeze(1)\n",
    "    signal1 = signal1.data\n",
    "    # Convert labels to tensor and move to GPU\n",
    "    optimizer.zero_grad()\n",
    "    embeddings1 = model(signal1)\n",
    "    output = clas(embeddings1)\n",
    "    print(output.shape)\n",
    "    print(labels.shape)\n",
    "    loss = criterion(output, labels)\n",
    "    print(loss)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "769b4170",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30, Training Loss: 0.052221337602550426\n",
      "Epoch 1/30, Validation Loss: 0.09677804583412554\n",
      "Model saved!\n",
      "Epoch 2/30, Training Loss: 0.0016915484258236033\n",
      "Epoch 2/30, Validation Loss: 0.08024667577779811\n",
      "Model saved!\n",
      "Epoch 3/30, Training Loss: 0.0008150713358375043\n",
      "Epoch 3/30, Validation Loss: 0.08101093056420587\n",
      "Epoch 4/30, Training Loss: 0.0005562579951137068\n",
      "Epoch 4/30, Validation Loss: 0.08202412839172714\n",
      "Epoch 5/30, Training Loss: 0.0004105561586388658\n",
      "Epoch 5/30, Validation Loss: 0.08210566590554011\n",
      "Epoch 6/30, Training Loss: 0.0003164770810708663\n",
      "Epoch 6/30, Validation Loss: 0.08042430546423142\n",
      "Epoch 7/30, Training Loss: 0.00025089047187895077\n",
      "Epoch 7/30, Validation Loss: 0.08309138129350604\n",
      "Epoch 8/30, Training Loss: 0.00020175675885115245\n",
      "Epoch 8/30, Validation Loss: 0.08014193997299646\n",
      "Model saved!\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[126], line 37\u001b[0m\n\u001b[1;32m     33\u001b[0m embeddings1 \u001b[38;5;241m=\u001b[39m model(features1)\n\u001b[1;32m     35\u001b[0m \u001b[38;5;66;03m# output = clas(embeddings1)\u001b[39;00m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;66;03m# Apply the AAM loss function\u001b[39;00m\n\u001b[0;32m---> 37\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mcriterion\u001b[49m\u001b[43m(\u001b[49m\u001b[43membeddings1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     39\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     40\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/pytorch_metric_learning/losses/base_metric_loss_function.py:34\u001b[0m, in \u001b[0;36mBaseMetricLossFunction.forward\u001b[0;34m(self, embeddings, labels, indices_tuple, ref_emb, ref_labels)\u001b[0m\n\u001b[1;32m     32\u001b[0m     labels \u001b[38;5;241m=\u001b[39m c_f\u001b[38;5;241m.\u001b[39mto_device(labels, embeddings)\n\u001b[1;32m     33\u001b[0m ref_emb, ref_labels \u001b[38;5;241m=\u001b[39m c_f\u001b[38;5;241m.\u001b[39mset_ref_emb(embeddings, labels, ref_emb, ref_labels)\n\u001b[0;32m---> 34\u001b[0m loss_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_loss\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[43m    \u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindices_tuple\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mref_emb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mref_labels\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_embedding_regularization_to_loss_dict(loss_dict, embeddings)\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreducer(loss_dict, embeddings, labels)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/pytorch_metric_learning/losses/generic_pair_loss.py:17\u001b[0m, in \u001b[0;36mGenericPairLoss.compute_loss\u001b[0;34m(self, embeddings, labels, indices_tuple, ref_emb, ref_labels)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_loss\u001b[39m(\u001b[38;5;28mself\u001b[39m, embeddings, labels, indices_tuple, ref_emb, ref_labels):\n\u001b[1;32m     16\u001b[0m     c_f\u001b[38;5;241m.\u001b[39mlabels_or_indices_tuple_required(labels, indices_tuple)\n\u001b[0;32m---> 17\u001b[0m     indices_tuple \u001b[38;5;241m=\u001b[39m \u001b[43mlmu\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_to_pairs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindices_tuple\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mref_labels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\u001b[38;5;28mlen\u001b[39m(x) \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m indices_tuple):\n\u001b[1;32m     19\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mzero_losses()\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/pytorch_metric_learning/utils/loss_and_miner_utils.py:65\u001b[0m, in \u001b[0;36mconvert_to_pairs\u001b[0;34m(indices_tuple, labels, ref_labels)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;124;03mThis returns anchor-positive and anchor-negative indices,\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;124;03mregardless of what the input indices_tuple is\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;124;03m    labels: a tensor which has the label for each element in a batch\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m indices_tuple \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mget_all_pairs_indices\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mref_labels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(indices_tuple) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m4\u001b[39m:\n\u001b[1;32m     67\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m indices_tuple\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/pytorch_metric_learning/utils/loss_and_miner_utils.py:50\u001b[0m, in \u001b[0;36mget_all_pairs_indices\u001b[0;34m(labels, ref_labels)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;124;03mGiven a tensor of labels, this will return 4 tensors.\u001b[39;00m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;124;03mThe first 2 tensors are the indices which form all positive pairs\u001b[39;00m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;124;03mThe second 2 tensors are the indices which form all negative pairs\u001b[39;00m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     49\u001b[0m matches, diffs \u001b[38;5;241m=\u001b[39m get_matches_and_diffs(labels, ref_labels)\n\u001b[0;32m---> 50\u001b[0m a1_idx, p_idx \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwhere\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmatches\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     51\u001b[0m a2_idx, n_idx \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mwhere(diffs)\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m a1_idx, p_idx, a2_idx, n_idx\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "early_stopping_patience = 8\n",
    "best_val_loss = float('inf')\n",
    "patience_counter = 0\n",
    "num_epochs = 30\n",
    "\n",
    "feature_maker = Fbank(n_mels = 80, left_frames=0, right_frames=0, deltas=False)\n",
    "norm = InputNormalization(norm_type = 'sentence', std_norm = False)\n",
    "cosine_sim = torch.nn.CosineSimilarity(dim=-1, eps=1e-6)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for batch in dataloader_train:\n",
    "        batch = batch.to(device)\n",
    "        signal1, lens1 = batch.signal1\n",
    "        labels = batch.lab\n",
    "        # Convert labels to tensor and move to GPU\n",
    "        # labels = torch.tensor(labels, dtype=torch.long).to(device)\n",
    "        # labels = labels.unsqueeze(1)\n",
    "        if len(signal1.shape) == 1:\n",
    "            signal1 = signal1.unsqueeze(0)\n",
    "    \n",
    "        if lens1 is None:\n",
    "            lens1 = torch.ones(signal1.shape[0], device=device)\n",
    "    \n",
    "        signal1, lens1 = signal1.to(device), lens1.to(device)\n",
    "        signal1 = signal1.float()\n",
    "        \n",
    "        features1 = feature_maker(signal1)    \n",
    "        features1 = norm(features1, lens1)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        embeddings1 = model(features1)\n",
    "\n",
    "        # output = clas(embeddings1)\n",
    "        # Apply the AAM loss function\n",
    "        loss = criterion(embeddings1, labels)\n",
    "                \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "    epoch_loss = running_loss / len(dataloader_train)\n",
    "    # scheduler.step()\n",
    "    checkpointer.save_and_keep_only(meta={\"loss\": loss.item()}, num_to_keep=1)\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}, Training Loss: {epoch_loss}')\n",
    "\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader_val:\n",
    "            batch = batch.to(device)\n",
    "            signal1, lens1 = batch.signal1\n",
    "            labels = batch.lab\n",
    "            # Convert labels to tensor and move to GPU\n",
    "            # labels = torch.tensor(labels, dtype=torch.long).to(device)\n",
    "            # labels = labels.unsqueeze(1)\n",
    "            if len(signal1.shape) == 1:\n",
    "                signal1 = signal1.unsqueeze(0)\n",
    "\n",
    "            \n",
    "        \n",
    "            if lens1 is None:\n",
    "                lens1 = torch.ones(signal1.shape[0], device=device)\n",
    "        \n",
    "            signal1, lens1 = signal1.to(device), lens1.to(device)\n",
    "            signal1 = signal1.float()\n",
    "            \n",
    "            features1 = feature_maker(signal1)    \n",
    "            features1 = norm(features1, lens1)\n",
    "            \n",
    "            embeddings1 = model(features1)\n",
    "    \n",
    "            # output = clas(embeddings1)\n",
    "            # Apply the AAM loss function\n",
    "            loss = criterion(embeddings1, labels)\n",
    "            val_loss += loss.item()\n",
    "    \n",
    "    val_loss /= len(dataloader_val)\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}, Validation Loss: {val_loss}')\n",
    "\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        patience_counter = 0\n",
    "        torch.save(model.state_dict(), \"fine_tuned_model.pth\")  # Save the best model\n",
    "        print(\"Model saved!\")\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        if patience_counter >= early_stopping_patience:\n",
    "            print(f\"Early stopping at epoch {epoch+1}\")\n",
    "            break\n",
    "\n",
    "torch.save(model.state_dict(), \"fine_tuned_model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "4617eaf2-cb57-4dde-81dd-66d8a347d728",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"fine_tuned_model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "51a04658",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to interpolate two models\n",
    "def interpolate_models(model1, model2, alpha):\n",
    "    # Ensure the models are on the same device\n",
    "    device = next(model1.parameters()).device\n",
    "    model2.to(device)\n",
    "    \n",
    "    # Create a new model with the same architecture\n",
    "    interpolated_model = type(model1)().to(device)\n",
    "    \n",
    "    # Interpolate the parameters\n",
    "    for param1, param2, param_interpolated in zip(model1.parameters(), model2.parameters(), interpolated_model.parameters()):\n",
    "        param_interpolated.data = alpha * param1.data + (1 - alpha) * param2.data\n",
    "    \n",
    "    # Interpolate the buffers (including BatchNorm running mean/var)\n",
    "    for buffer1, buffer2, buffer_interpolated in zip(model1.buffers(), model2.buffers(), interpolated_model.buffers()):\n",
    "        buffer_interpolated.data = alpha * buffer1.data + (1 - alpha) * buffer2.data\n",
    "    \n",
    "    return interpolated_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "d66fffe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "from speechbrain.lobes.models.ResNet import ResNet\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "pretrained_model = ResNet(input_size=80, \n",
    "               device=device, \n",
    "               channels=[128, 128, 256, 256], \n",
    "               block_sizes=[3, 4, 6, 3], \n",
    "               strides=[1, 2, 2, 2], \n",
    "               lin_neurons=256)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "254d2d32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(1, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (activation1): ReLU()\n",
       "  (layer1): Sequential(\n",
       "    (0): SEBasicBlock(\n",
       "      (activation): ReLU()\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (se): SEBlock(\n",
       "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): SEBasicBlock(\n",
       "      (activation): ReLU()\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (se): SEBlock(\n",
       "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (2): SEBasicBlock(\n",
       "      (activation): ReLU()\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (se): SEBlock(\n",
       "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): SEBasicBlock(\n",
       "      (activation): ReLU()\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (se): SEBlock(\n",
       "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): SEBasicBlock(\n",
       "      (activation): ReLU()\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (se): SEBlock(\n",
       "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (2): SEBasicBlock(\n",
       "      (activation): ReLU()\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (se): SEBlock(\n",
       "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (3): SEBasicBlock(\n",
       "      (activation): ReLU()\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (se): SEBlock(\n",
       "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (activation): ReLU()\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (activation): ReLU()\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (activation): ReLU()\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    )\n",
       "    (3): BasicBlock(\n",
       "      (activation): ReLU()\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    )\n",
       "    (4): BasicBlock(\n",
       "      (activation): ReLU()\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    )\n",
       "    (5): BasicBlock(\n",
       "      (activation): ReLU()\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (activation): ReLU()\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (activation): ReLU()\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (activation): ReLU()\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    )\n",
       "  )\n",
       "  (norm_stats): BatchNorm1d(5120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (attention): Sequential(\n",
       "    (0): Conv1d(2560, 128, kernel_size=(1,), stride=(1,))\n",
       "    (1): ReLU()\n",
       "    (2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): Conv1d(128, 2560, kernel_size=(1,), stride=(1,))\n",
       "    (4): Softmax(dim=2)\n",
       "  )\n",
       "  (fc_embed): Linear(in_features=5120, out_features=256, bias=True)\n",
       "  (norm_embed): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       ")"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from speechbrain.utils.parameter_transfer import Pretrainer\n",
    "pretrain = Pretrainer(loadables={'model': pretrained_model}, paths={'model': 'speechbrain/spkrec-resnet-voxceleb/embedding_model.ckpt'})\n",
    "\n",
    "# We download the pretrained model from HuggingFace in this case\n",
    "pretrain.collect_files()\n",
    "pretrain.load_collected()\n",
    "\n",
    "\n",
    "pretrained_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "434a801c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(1, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (activation1): ReLU()\n",
       "  (layer1): Sequential(\n",
       "    (0): SEBasicBlock(\n",
       "      (activation): ReLU()\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (se): SEBlock(\n",
       "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): SEBasicBlock(\n",
       "      (activation): ReLU()\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (se): SEBlock(\n",
       "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (2): SEBasicBlock(\n",
       "      (activation): ReLU()\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (se): SEBlock(\n",
       "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): SEBasicBlock(\n",
       "      (activation): ReLU()\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (se): SEBlock(\n",
       "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): SEBasicBlock(\n",
       "      (activation): ReLU()\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (se): SEBlock(\n",
       "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (2): SEBasicBlock(\n",
       "      (activation): ReLU()\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (se): SEBlock(\n",
       "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (3): SEBasicBlock(\n",
       "      (activation): ReLU()\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (se): SEBlock(\n",
       "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (activation): ReLU()\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (activation): ReLU()\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (activation): ReLU()\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    )\n",
       "    (3): BasicBlock(\n",
       "      (activation): ReLU()\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    )\n",
       "    (4): BasicBlock(\n",
       "      (activation): ReLU()\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    )\n",
       "    (5): BasicBlock(\n",
       "      (activation): ReLU()\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (activation): ReLU()\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (activation): ReLU()\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (activation): ReLU()\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    )\n",
       "  )\n",
       "  (norm_stats): BatchNorm1d(5120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (attention): Sequential(\n",
       "    (0): Conv1d(2560, 128, kernel_size=(1,), stride=(1,))\n",
       "    (1): ReLU()\n",
       "    (2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): Conv1d(128, 2560, kernel_size=(1,), stride=(1,))\n",
       "    (4): Softmax(dim=2)\n",
       "  )\n",
       "  (fc_embed): Linear(in_features=5120, out_features=256, bias=True)\n",
       "  (norm_embed): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       ")"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finetuned_model = ResNet(input_size=80, \n",
    "               device=device, \n",
    "               channels=[128, 128, 256, 256], \n",
    "               block_sizes=[3, 4, 6, 3], \n",
    "               strides=[1, 2, 2, 2], \n",
    "               lin_neurons=256)\n",
    "finetuned_model.load_state_dict(torch.load(\"fine_tuned_model.pth\"))\n",
    "finetuned_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "693aa48e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(1, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (activation1): ReLU()\n",
       "  (layer1): Sequential(\n",
       "    (0): SEBasicBlock(\n",
       "      (activation): ReLU()\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (se): SEBlock(\n",
       "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): SEBasicBlock(\n",
       "      (activation): ReLU()\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (se): SEBlock(\n",
       "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (2): SEBasicBlock(\n",
       "      (activation): ReLU()\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (se): SEBlock(\n",
       "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): SEBasicBlock(\n",
       "      (activation): ReLU()\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (se): SEBlock(\n",
       "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): SEBasicBlock(\n",
       "      (activation): ReLU()\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (se): SEBlock(\n",
       "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (2): SEBasicBlock(\n",
       "      (activation): ReLU()\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (se): SEBlock(\n",
       "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (3): SEBasicBlock(\n",
       "      (activation): ReLU()\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (se): SEBlock(\n",
       "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (activation): ReLU()\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (activation): ReLU()\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (activation): ReLU()\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    )\n",
       "    (3): BasicBlock(\n",
       "      (activation): ReLU()\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    )\n",
       "    (4): BasicBlock(\n",
       "      (activation): ReLU()\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    )\n",
       "    (5): BasicBlock(\n",
       "      (activation): ReLU()\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (activation): ReLU()\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (activation): ReLU()\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (activation): ReLU()\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    )\n",
       "  )\n",
       "  (norm_stats): BatchNorm1d(5120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (attention): Sequential(\n",
       "    (0): Conv1d(2560, 128, kernel_size=(1,), stride=(1,))\n",
       "    (1): ReLU()\n",
       "    (2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): Conv1d(128, 2560, kernel_size=(1,), stride=(1,))\n",
       "    (4): Softmax(dim=2)\n",
       "  )\n",
       "  (fc_embed): Linear(in_features=5120, out_features=256, bias=True)\n",
       "  (norm_embed): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       ")"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha = 0.3  # Change alpha as needed\n",
    "interpolated_model = interpolate_models(pretrained_model, finetuned_model, alpha)\n",
    "\n",
    "# Move the interpolated model to the device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "interpolated_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "b781e117-aaab-48e0-9337-7488669a2f54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[[[ 0.0905,  0.2573,  0.3710],\n",
      "          [ 0.1229,  0.7042,  1.0147],\n",
      "          [ 0.1084, -0.1089,  0.6465]]],\n",
      "\n",
      "\n",
      "        [[[-0.0724,  0.1205,  0.1229],\n",
      "          [-0.0572, -0.0666,  0.0087],\n",
      "          [-0.3296, -0.4549, -0.3854]]],\n",
      "\n",
      "\n",
      "        [[[-0.1603,  0.0503, -0.2438],\n",
      "          [-0.2613, -0.1426, -0.2535],\n",
      "          [-0.1318, -0.2272,  0.1841]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.0702, -0.0602, -0.3591],\n",
      "          [ 0.0137, -0.1686,  1.3274],\n",
      "          [ 0.0493,  0.0901, -0.6045]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1862, -0.8853,  0.3028],\n",
      "          [ 0.0665, -0.4076,  0.1459],\n",
      "          [-0.3951,  0.2630, -0.0063]]],\n",
      "\n",
      "\n",
      "        [[[-0.3060, -0.0299,  0.3859],\n",
      "          [-0.7436, -0.2048,  0.7486],\n",
      "          [-0.5148, -0.0582,  0.6231]]]], device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[[[ 0.0893,  0.2528,  0.3696],\n",
      "          [ 0.1233,  0.7026,  1.0174],\n",
      "          [ 0.1099, -0.1096,  0.6480]]],\n",
      "\n",
      "\n",
      "        [[[-0.0793,  0.1139,  0.1170],\n",
      "          [-0.0640, -0.0742,  0.0018],\n",
      "          [-0.3315, -0.4631, -0.3826]]],\n",
      "\n",
      "\n",
      "        [[[-0.1661,  0.0462, -0.2447],\n",
      "          [-0.2639, -0.1409, -0.2534],\n",
      "          [-0.1283, -0.2233,  0.1869]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.0720, -0.0609, -0.3598],\n",
      "          [ 0.0125, -0.1697,  1.3261],\n",
      "          [ 0.0476,  0.0881, -0.6066]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1867, -0.8853,  0.3028],\n",
      "          [ 0.0646, -0.4102,  0.1447],\n",
      "          [-0.3977,  0.2585, -0.0091]]],\n",
      "\n",
      "\n",
      "        [[[-0.3037, -0.0277,  0.3882],\n",
      "          [-0.7420, -0.2032,  0.7504],\n",
      "          [-0.5130, -0.0565,  0.6246]]]], device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[[[ 9.3229e-02,  2.6782e-01,  3.7409e-01],\n",
      "          [ 1.2204e-01,  7.0803e-01,  1.0085e+00],\n",
      "          [ 1.0471e-01, -1.0736e-01,  6.4299e-01]]],\n",
      "\n",
      "\n",
      "        [[[-5.6455e-02,  1.3594e-01,  1.3659e-01],\n",
      "          [-4.1282e-02, -4.9004e-02,  2.4805e-02],\n",
      "          [-3.2530e-01, -4.3558e-01, -3.9194e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.4673e-01,  5.9640e-02, -2.4165e-01],\n",
      "          [-2.5523e-01, -1.4672e-01, -2.5362e-01],\n",
      "          [-1.4006e-01, -2.3628e-01,  1.7775e-01]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-6.6193e-02, -5.8602e-02, -3.5745e-01],\n",
      "          [ 1.6404e-02, -1.6611e-01,  1.3305e+00],\n",
      "          [ 5.3128e-02,  9.4664e-02, -5.9976e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.8516e-01, -8.8534e-01,  3.0261e-01],\n",
      "          [ 7.0862e-02, -4.0142e-01,  1.4878e-01],\n",
      "          [-3.8899e-01,  2.7355e-01,  3.7536e-04]]],\n",
      "\n",
      "\n",
      "        [[[-3.1143e-01, -3.4939e-02,  3.8040e-01],\n",
      "          [-7.4744e-01, -2.0855e-01,  7.4435e-01],\n",
      "          [-5.1888e-01, -6.2122e-02,  6.1947e-01]]]], device='cuda:0',\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for param in interpolated_model.parameters():\n",
    "    print(param)\n",
    "    break\n",
    "\n",
    "for param in finetuned_model.parameters():\n",
    "    print(param)\n",
    "    break\n",
    "for param in pretrained_model.parameters():\n",
    "    print(param)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "0f2a64a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(interpolated_model.state_dict(), \"interpolated_model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "8b2e5e8b-3d41-45cb-913d-d3a89639a9c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "@speechbrain.utils.data_pipeline.takes(\"file1\", \"file2\", \"label\")\n",
    "@speechbrain.utils.data_pipeline.provides(\"signal1\", \"signal2\", \"lab\")\n",
    "def audio_pipeline_verification(file1, file2, label, max_duration=1000):\n",
    "    waveform1, sample_rate1 = torchaudio.load(file1.replace(\"\\\\\", \"/\"))\n",
    "    waveform2, sample_rate2 = torchaudio.load(file2.replace(\"\\\\\", \"/\"))\n",
    "    # feature_maker = Fbank(n_mels = 80)\n",
    "    # norm = InputNormalization(norm_type = 'sentence', std_norm = False)\n",
    "\n",
    "    # Resample the audio to 16 kHz if needed\n",
    "    # resampler = speechbrain.augment.time_domain.Resample(orig_freq=sample_rate1, new_freq=16000)\n",
    "    # waveform1 = resampler(waveform1)\n",
    "    # waveform2 = resampler(waveform2)\n",
    "    \n",
    "    # Limit the duration if needed\n",
    "    max_samples = int(max_duration * 16000)  # Maximum number of samples allowed\n",
    "    if waveform1.size(1) > max_samples:\n",
    "        waveform1 = waveform1[:, :max_samples]\n",
    "    if waveform2.size(1) > max_samples:\n",
    "        waveform2 = waveform2[:, :max_samples]\n",
    "\n",
    "    waveform1 = waveform1.transpose(0, 1).squeeze(1)\n",
    "    waveform2 = waveform2.transpose(0, 1).squeeze(1)\n",
    "\n",
    "    # Convert labels from 'true'/'false' to 1/0\n",
    "    # label = 1 if label == 'True' else 0\n",
    "   \n",
    "    \n",
    "    # features1 = feature_maker(waveform1)\n",
    "    # features2 = feature_maker(waveform2)\n",
    "    \n",
    "    # inp_len1 = torch.Tensor([features1.shape[1]])\n",
    "    # inp_len2 = torch.Tensor([features2.shape[1]])\n",
    "    # features1 = norm(features1, features1.lens)\n",
    "    # features2 = norm(features2, features2.lens)\n",
    "\n",
    "    return waveform1, waveform2, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "b8745d12-8e8a-4ada-b532-01cb35df4b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_ver = DynamicItemDataset.from_csv(\"Wyred-pairs-nolarge-cut.csv\") # or equivalently, DynamicItemDataset.from_csv(\"data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "f707091d-a139-46f0-95cc-035842fedc69",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_ver.add_dynamic_item(audio_pipeline_verification)\n",
    "dataset_ver.set_output_keys([\"signal1\", \"signal2\", \"lab\"])\n",
    "dataloader_test = SaveableDataLoader(dataset_ver, batch_size=2, collate_fn=PaddedBatch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "f364ef26-7c2d-445a-8345-23d187ad3f6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'signal1': tensor([-0.0009, -0.0009,  0.0000,  ...,  0.0009,  0.0046,  0.0083]),\n",
       " 'signal2': tensor([ 0.0102,  0.0103,  0.0119,  ..., -0.0002,  0.0002,  0.0002]),\n",
       " 'lab': 'True'}"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_ver[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "f2ac4434-3eab-4aca-acfd-23be7f887f11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(1, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (activation1): ReLU()\n",
       "  (layer1): Sequential(\n",
       "    (0): SEBasicBlock(\n",
       "      (activation): ReLU()\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (se): SEBlock(\n",
       "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): SEBasicBlock(\n",
       "      (activation): ReLU()\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (se): SEBlock(\n",
       "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (2): SEBasicBlock(\n",
       "      (activation): ReLU()\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (se): SEBlock(\n",
       "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): SEBasicBlock(\n",
       "      (activation): ReLU()\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (se): SEBlock(\n",
       "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): SEBasicBlock(\n",
       "      (activation): ReLU()\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (se): SEBlock(\n",
       "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (2): SEBasicBlock(\n",
       "      (activation): ReLU()\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (se): SEBlock(\n",
       "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (3): SEBasicBlock(\n",
       "      (activation): ReLU()\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (se): SEBlock(\n",
       "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (activation): ReLU()\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (activation): ReLU()\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (activation): ReLU()\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    )\n",
       "    (3): BasicBlock(\n",
       "      (activation): ReLU()\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    )\n",
       "    (4): BasicBlock(\n",
       "      (activation): ReLU()\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    )\n",
       "    (5): BasicBlock(\n",
       "      (activation): ReLU()\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (activation): ReLU()\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (activation): ReLU()\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (activation): ReLU()\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    )\n",
       "  )\n",
       "  (norm_stats): BatchNorm1d(5120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (attention): Sequential(\n",
       "    (0): Conv1d(2560, 128, kernel_size=(1,), stride=(1,))\n",
       "    (1): ReLU()\n",
       "    (2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): Conv1d(128, 2560, kernel_size=(1,), stride=(1,))\n",
       "    (4): Softmax(dim=2)\n",
       "  )\n",
       "  (fc_embed): Linear(in_features=5120, out_features=256, bias=True)\n",
       "  (norm_embed): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       ")"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from speechbrain.lobes.models.ResNet import ResNet\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "pretrained_model = ResNet(input_size=80, \n",
    "               device=device, \n",
    "               channels=[128, 128, 256, 256], \n",
    "               block_sizes=[3, 4, 6, 3], \n",
    "               strides=[1, 2, 2, 2], \n",
    "               lin_neurons=256)\n",
    "\n",
    "pretrainer = speechbrain.utils.parameter_transfer.Pretrainer(loadables={'model': pretrained_model}, paths={'model': 'speechbrain/spkrec-resnet-voxceleb/embedding_model.ckpt'})\n",
    "pretrainer.collect_files\n",
    "pretrainer.load_collected()\n",
    "\n",
    "pretrained_model.eval()\n",
    "pretrained_model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "246edfcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ivbeveren/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n",
      "/home/ivbeveren/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 6.96 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n",
      "/home/ivbeveren/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 13.92 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n",
      "/home/ivbeveren/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 20.89 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n",
      "/home/ivbeveren/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 13.93 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n",
      "/home/ivbeveren/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 6.50 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n",
      "/home/ivbeveren/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 13.00 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n",
      "/home/ivbeveren/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 19.50 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n",
      "/home/ivbeveren/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 6.38 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n",
      "/home/ivbeveren/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 12.76 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n",
      "/home/ivbeveren/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 19.14 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n",
      "/home/ivbeveren/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 12.77 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n",
      "/home/ivbeveren/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 19.15 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n",
      "/home/ivbeveren/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 6.80 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n",
      "/home/ivbeveren/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 13.61 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n",
      "/home/ivbeveren/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 20.41 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n",
      "/home/ivbeveren/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 20.42 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n",
      "/home/ivbeveren/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 7.57 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n",
      "/home/ivbeveren/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 15.13 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n",
      "/home/ivbeveren/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 22.70 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n",
      "/home/ivbeveren/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 5.85 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n",
      "/home/ivbeveren/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 11.70 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n",
      "/home/ivbeveren/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 17.54 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n",
      "/home/ivbeveren/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 17.55 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n",
      "/home/ivbeveren/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 7.17 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n",
      "/home/ivbeveren/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 14.35 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n",
      "/home/ivbeveren/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 21.52 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n",
      "/home/ivbeveren/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 6.46 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n",
      "/home/ivbeveren/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 12.92 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n",
      "/home/ivbeveren/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 19.39 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n",
      "/home/ivbeveren/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 12.93 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n",
      "/home/ivbeveren/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 6.30 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n",
      "/home/ivbeveren/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 12.59 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n",
      "/home/ivbeveren/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 18.89 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n",
      "/home/ivbeveren/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 6.31 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n",
      "/home/ivbeveren/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 12.62 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n",
      "/home/ivbeveren/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 18.92 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n",
      "/home/ivbeveren/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 18.93 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n",
      "/home/ivbeveren/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 7.30 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n",
      "/home/ivbeveren/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 14.60 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n",
      "/home/ivbeveren/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 21.90 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n",
      "/home/ivbeveren/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 5.86 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n",
      "/home/ivbeveren/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 11.72 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n",
      "/home/ivbeveren/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 17.58 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n",
      "/home/ivbeveren/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 5.80 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n",
      "/home/ivbeveren/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 11.61 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n",
      "/home/ivbeveren/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 17.41 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n",
      "/home/ivbeveren/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 6.91 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n",
      "/home/ivbeveren/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 13.82 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n",
      "/home/ivbeveren/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 20.73 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n",
      "/home/ivbeveren/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 6.07 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n",
      "/home/ivbeveren/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 12.15 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n",
      "/home/ivbeveren/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 18.22 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n",
      "/home/ivbeveren/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 6.12 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n",
      "/home/ivbeveren/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 12.25 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n",
      "/home/ivbeveren/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 18.37 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n",
      "/home/ivbeveren/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 18.38 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n",
      "/home/ivbeveren/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 6.95 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n",
      "/home/ivbeveren/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 13.90 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n",
      "/home/ivbeveren/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 20.85 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n",
      "/home/ivbeveren/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 20.86 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n",
      "/home/ivbeveren/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 7.46 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n",
      "/home/ivbeveren/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 14.93 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n",
      "/home/ivbeveren/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 22.39 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n",
      "/home/ivbeveren/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 6.22 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n",
      "/home/ivbeveren/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 12.44 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n",
      "/home/ivbeveren/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 18.66 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n",
      "/home/ivbeveren/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 7.42 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n",
      "/home/ivbeveren/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 14.83 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n",
      "/home/ivbeveren/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 22.25 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n",
      "/home/ivbeveren/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 14.61 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n",
      "/home/ivbeveren/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 21.91 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n",
      "/home/ivbeveren/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 6.39 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n",
      "/home/ivbeveren/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 12.78 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n",
      "/home/ivbeveren/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 19.18 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n",
      "/home/ivbeveren/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 12.79 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n",
      "/home/ivbeveren/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 7.29 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n",
      "/home/ivbeveren/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 14.58 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n",
      "/home/ivbeveren/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 21.87 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n",
      "/home/ivbeveren/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 21.88 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n",
      "/home/ivbeveren/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 6.79 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n",
      "/home/ivbeveren/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 13.57 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n",
      "/home/ivbeveren/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 20.36 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n",
      "/home/ivbeveren/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 6.83 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n",
      "/home/ivbeveren/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 13.65 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n",
      "/home/ivbeveren/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 20.47 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n",
      "/home/ivbeveren/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 20.48 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n",
      "/home/ivbeveren/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 5.94 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n",
      "/home/ivbeveren/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 11.88 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n",
      "/home/ivbeveren/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 17.82 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n",
      "/home/ivbeveren/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 5.65 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n",
      "/home/ivbeveren/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 11.30 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n",
      "/home/ivbeveren/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 16.95 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n",
      "/home/ivbeveren/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 6.26 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n",
      "/home/ivbeveren/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 12.51 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n",
      "/home/ivbeveren/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 18.76 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n",
      "/home/ivbeveren/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 18.77 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n",
      "/home/ivbeveren/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 6.43 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n",
      "/home/ivbeveren/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 12.85 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n",
      "/home/ivbeveren/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 19.28 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n",
      "/home/ivbeveren/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 12.86 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n",
      "/home/ivbeveren/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 6.19 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n",
      "/home/ivbeveren/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 12.38 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n",
      "/home/ivbeveren/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 18.58 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n",
      "/home/ivbeveren/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 12.39 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n",
      "/home/ivbeveren/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 11.87 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n",
      "/home/ivbeveren/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 17.81 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n",
      "/home/ivbeveren/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 7.36 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n",
      "/home/ivbeveren/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 14.72 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n",
      "/home/ivbeveren/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 22.09 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n",
      "/home/ivbeveren/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 14.73 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n",
      "/home/ivbeveren/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 7.05 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n",
      "/home/ivbeveren/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 14.10 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n",
      "/home/ivbeveren/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 21.14 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n",
      "/home/ivbeveren/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 21.15 GiB. GPU  (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:924.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n"
     ]
    }
   ],
   "source": [
    "predicted_labels = []\n",
    "scores = []\n",
    "true_labels = []\n",
    "outputs = []\n",
    "\n",
    "feature_maker = Fbank(n_mels = 80)\n",
    "norm = InputNormalization(norm_type = 'sentence', std_norm = False)\n",
    "cosine_sim = torch.nn.CosineSimilarity(dim=-1, eps=1e-6)\n",
    "finetuned_model.eval()\n",
    "interpolated_model.eval()\n",
    "for batch in iter(dataloader_test):\n",
    "    batch = batch.to(device)\n",
    "    signal1, lens1 = batch.signal1\n",
    "    signal2, lens2 = batch.signal2\n",
    "    labels = batch.lab\n",
    "\n",
    "    # Convert labels to tensor and move to GPU\n",
    "    # labels = torch.tensor(labels, dtype=torch.long).to(device)\n",
    "    if len(signal1.shape) == 1:\n",
    "        signal1 = signal1.unsqueeze(0)\n",
    "\n",
    "    if lens1 is None:\n",
    "        lens1 = torch.ones(signal1.shape[0], device=device)\n",
    "\n",
    "    if len(signal2.shape) == 1:\n",
    "        signal2 = signal2.unsqueeze(0)\n",
    "\n",
    "    if lens2 is None:\n",
    "        lens2 = torch.ones(signal2.shape[0], device=device)\n",
    "\n",
    "    signal1, lens1 = signal1.to(device), lens1.to(device)\n",
    "    signal1 = signal1.float()\n",
    "\n",
    "    signal2, lens2 = signal2.to(device), lens2.to(device)\n",
    "    signal2 = signal2.float()\n",
    "\n",
    "    features1 = feature_maker(signal1)\n",
    "    features2 = feature_maker(signal2)\n",
    "\n",
    "    features1 = norm(features1, lens1)\n",
    "    features2 = norm(features2, lens2)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        embeddings1 = interpolated_model(features1)\n",
    "        embeddings2 = interpolated_model(features2)\n",
    "\n",
    "        # embeddings1 = torch.nn.functional.normalize(embeddings1, dim=-1).cpu()\n",
    "        # embeddings2 = torch.nn.functional.normalize(embeddings2, dim=-1).cpu()\n",
    "\n",
    "    # Compute cosine similarity and classify\n",
    "    score = cosine_sim(embeddings1, embeddings2)\n",
    "    prediction = (score > 0.25).long()\n",
    "    \n",
    "    # Threshold can be adjusted\n",
    "    outputs.append((score, prediction, batch[\"lab\"]))\n",
    "    # Convert predictions to labels\n",
    "#     batch_predicted_labels = [True if pred == 1 else False for pred in predictions]\n",
    "    # predicted_labels.extend(predictions.to('cpu'))\n",
    "    # true_labels.extend(labels.to('cpu'))\n",
    "    # scores.extend(similarities.to('cpu'))\n",
    "\n",
    "#     outputs.append((score, prediction, batch[\"label\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "94bec180-15a8-4be1-9470-9581daa1fd6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores, X, y = zip(*outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "bb753953",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " ...]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "y = sum(list(y), [])\n",
    "X = [value for sublist in X for value in sublist]\n",
    "X = [t.item() for t in X]\n",
    "\n",
    "scores = [value for sublist in scores for value in sublist]\n",
    "scores = [t.item() for t in scores]\n",
    "\n",
    "def str_to_bool(s):\n",
    "    if s == 'True':\n",
    "         return True\n",
    "    elif s == 'False':\n",
    "         return False\n",
    "\n",
    "y = list(map(str_to_bool, y))\n",
    "\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "1ed48385",
   "metadata": {},
   "outputs": [],
   "source": [
    "def str_to_bool(s):\n",
    "    if s == 'True':\n",
    "         return True\n",
    "    elif s == 'False':\n",
    "         return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "f36867eb-fda5-4c63-a9b0-0254490ce4fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "345aed27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from operator import itemgetter\n",
    "from scipy.optimize import brentq\n",
    "from sklearn.metrics import roc_curve\n",
    "from scipy.interpolate import interp1d\n",
    "\n",
    "def calculate_eer(y, y_score, pos):\n",
    "# y denotes groundtruth scores,\n",
    "# y_score denotes the prediction scores.\n",
    "\n",
    "    fpr, tpr, thresholds = roc_curve(y, y_score, pos_label=pos)\n",
    "    eer = brentq(lambda x : 1. - x - interp1d(fpr, tpr)(x), 0., 1.)\n",
    "    thresh = interp1d(fpr, thresholds)(eer)\n",
    "\n",
    "    return eer, thresh, fpr, tpr\n",
    "\n",
    "# Creates a list of false-negative rates, a list of false-positive rates\n",
    "# and a list of decision thresholds that give those error-rates.\n",
    "def ComputeErrorRates(scores, labels):\n",
    "\n",
    "    # Sort the scores from smallest to largest, and also get the corresponding\n",
    "    # indexes of the sorted scores.  We will treat the sorted scores as the\n",
    "    # thresholds at which the the error-rates are evaluated.\n",
    "    sorted_indexes, thresholds = zip(*sorted(\n",
    "        [(index, threshold) for index, threshold in enumerate(scores)],\n",
    "        key=itemgetter(1)))\n",
    "    sorted_labels = []\n",
    "    labels = [labels[i] for i in sorted_indexes]\n",
    "    fnrs = []\n",
    "    fprs = []\n",
    "\n",
    "    # At the end of this loop, fnrs[i] is the number of errors made by\n",
    "    # incorrectly rejecting scores less than thresholds[i]. And, fprs[i]\n",
    "    # is the total number of times that we have correctly accepted scores\n",
    "    # greater than thresholds[i].\n",
    "    for i in range(0, len(labels)):\n",
    "        if i == 0:\n",
    "            fnrs.append(labels[i])\n",
    "            fprs.append(1 - labels[i])\n",
    "        else:\n",
    "            fnrs.append(fnrs[i-1] + labels[i])\n",
    "            fprs.append(fprs[i-1] + 1 - labels[i])\n",
    "    fnrs_norm = sum(labels)\n",
    "    fprs_norm = len(labels) - fnrs_norm\n",
    "\n",
    "    # Now divide by the total number of false negative errors to\n",
    "    # obtain the false positive rates across all thresholds\n",
    "    fnrs = [x / float(fnrs_norm) for x in fnrs]\n",
    "\n",
    "    # Divide by the total number of corret positives to get the\n",
    "    # true positive rate.  Subtract these quantities from 1 to\n",
    "    # get the false positive rates.\n",
    "    fprs = [1 - x / float(fprs_norm) for x in fprs]\n",
    "    return fnrs, fprs, thresholds\n",
    "\n",
    "# Computes the minimum of the detection cost function.  The comments refer to\n",
    "# equations in Section 3 of the NIST 2016 Speaker Recognition Evaluation Plan.\n",
    "def ComputeMinDcf(fnrs, fprs, thresholds, p_target, c_miss, c_fa):\n",
    "    min_c_det = float(\"inf\")\n",
    "    min_c_det_threshold = thresholds[0]\n",
    "    for i in range(0, len(fnrs)):\n",
    "        # See Equation (2).  it is a weighted sum of false negative\n",
    "        # and false positive errors.\n",
    "        c_det = c_miss * fnrs[i] * p_target + c_fa * fprs[i] * (1 - p_target)\n",
    "        if c_det < min_c_det:\n",
    "            min_c_det = c_det\n",
    "            min_c_det_threshold = thresholds[i]\n",
    "    # See Equations (3) and (4).  Now we normalize the cost.\n",
    "    c_def = min(c_miss * p_target, c_fa * (1 - p_target))\n",
    "    min_dcf = min_c_det / c_def\n",
    "    return min_dcf, min_c_det_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "8a9941b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER : 17.00%\n"
     ]
    }
   ],
   "source": [
    "eer, thresh, fpr, tpr = calculate_eer(y, scores, pos=1)\n",
    "print('EER : %.2f%%'%(eer*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "28be8f15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minDCF : 0.5584, at threshold 0.7521 (p-target=0.01, c-miss=1, c-fa=1)\n"
     ]
    }
   ],
   "source": [
    "c_miss = 1\n",
    "c_fa = 1\n",
    "p_target = 0.01\n",
    "\n",
    "fnrs, fprs, thresholds = ComputeErrorRates(scores,\n",
    "                                           y)\n",
    "mindcf, threshold_default = ComputeMinDcf(fnrs, fprs, thresholds, p_target, c_miss, c_fa)\n",
    "\n",
    "print(\"minDCF : {0:.4f}, at threshold {1:.4f} (p-target={2}, c-miss={3}, \"\n",
    "    \"c-fa={4})\".format(mindcf, threshold_default, p_target,c_miss, c_fa))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "06051357",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(finetuned_model.state_dict(), \"best_finetuned_model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f2ba8d9c-8114-48c5-869b-68bdda47df6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model):\n",
    "    predicted_labels = []\n",
    "    scores = []\n",
    "    true_labels = []\n",
    "    outputs = []\n",
    "    \n",
    "    feature_maker = Fbank(n_mels = 80)\n",
    "    norm = InputNormalization(norm_type = 'sentence', std_norm = False)\n",
    "    cosine_sim = torch.nn.CosineSimilarity(dim=-1, eps=1e-6)\n",
    "    model.eval()\n",
    "    for batch in iter(dataloader_test):\n",
    "        batch = batch.to(device)\n",
    "        signal1, lens1 = batch.signal1\n",
    "        signal2, lens2 = batch.signal2\n",
    "        labels = batch.lab\n",
    "    \n",
    "        # Convert labels to tensor and move to GPU\n",
    "        # labels = torch.tensor(labels, dtype=torch.long).to(device)\n",
    "        if len(signal1.shape) == 1:\n",
    "            signal1 = signal1.unsqueeze(0)\n",
    "    \n",
    "        if lens1 is None:\n",
    "            lens1 = torch.ones(signal1.shape[0], device=device)\n",
    "    \n",
    "        if len(signal2.shape) == 1:\n",
    "            signal2 = signal2.unsqueeze(0)\n",
    "    \n",
    "        if lens2 is None:\n",
    "            lens2 = torch.ones(signal2.shape[0], device=device)\n",
    "    \n",
    "        signal1, lens1 = signal1.to(device), lens1.to(device)\n",
    "        signal1 = signal1.float()\n",
    "    \n",
    "        signal2, lens2 = signal2.to(device), lens2.to(device)\n",
    "        signal2 = signal2.float()\n",
    "    \n",
    "        features1 = feature_maker(signal1)\n",
    "        features2 = feature_maker(signal2)\n",
    "    \n",
    "        features1 = norm(features1, lens1)\n",
    "        features2 = norm(features2, lens2)\n",
    "    \n",
    "        with torch.no_grad():\n",
    "            embeddings1 = model(features1)\n",
    "            embeddings2 = model(features2)\n",
    "    \n",
    "            # embeddings1 = torch.nn.functional.normalize(embeddings1, dim=-1).cpu()\n",
    "            # embeddings2 = torch.nn.functional.normalize(embeddings2, dim=-1).cpu()\n",
    "    \n",
    "        # Compute cosine similarity and classify\n",
    "        score = cosine_sim(embeddings1, embeddings2)\n",
    "        prediction = (score > 0.25).long()\n",
    "        \n",
    "        # Threshold can be adjusted\n",
    "        outputs.append((score, prediction, batch[\"lab\"]))\n",
    "\n",
    "    scores, X, y = zip(*outputs)\n",
    "    y = sum(list(y), [])\n",
    "    X = [value for sublist in X for value in sublist]\n",
    "    X = [t.item() for t in X]\n",
    "    \n",
    "    scores = [value for sublist in scores for value in sublist]\n",
    "    scores = [t.item() for t in scores]\n",
    "    y = list(map(str_to_bool, y))\n",
    "    c_miss = 1\n",
    "    c_fa = 1\n",
    "    p_target = 0.01\n",
    "    eer, thresh, fpr, tpr = calculate_eer(y, scores, pos=1)\n",
    "    fnrs, fprs, thresholds = ComputeErrorRates(scores,\n",
    "                                           y)\n",
    "    mindcf, threshold_default = ComputeMinDcf(fnrs, fprs, thresholds, p_target, c_miss, c_fa)\n",
    "    return eer, mindcf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8da636c0-bd74-4c7f-be93-0daa748b016c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results at alpha = 0.1: 0.006681514476614676, 0.0200445434298441\n",
      "Results at alpha = 0.2: 0.00655021833976097, 0.013363028953229397\n",
      "Results at alpha = 0.3: 0.004454342984574699, 0.011135857461024499\n",
      "Results at alpha = 0.4: 0.004454342984409785, 0.013363028953229397\n",
      "Results at alpha = 0.5: 0.006681514476688931, 0.011135857461024499\n",
      "Results at alpha = 0.6: 0.006681514476614663, 0.013363028953229397\n",
      "Results at alpha = 0.7: 0.006681514476859302, 0.015590200445434297\n",
      "Results at alpha = 0.8: 0.008908685968819875, 0.024498886414253896\n",
      "Results at alpha = 0.9: 0.01091703056791552, 0.028953229398663696\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "alphas = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "for alpha in alphas:\n",
    "    interpolated_model = interpolate_models(pretrained_model, finetuned_model, alpha)\n",
    "    eer, mindcf = predict(interpolated_model)\n",
    "    results.append((alpha, eer, mindcf))\n",
    "    print(\"Results at alpha = \" + str(alpha) + \": \" + str(eer) + \", \" + str(mindcf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "287f1653-416b-4b26-971f-7d1135ee3288",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting seaborn\n",
      "  Downloading seaborn-0.13.2-py3-none-any.whl (294 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.9/294.9 kB\u001b[0m \u001b[31m32.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy!=1.24.0,>=1.20 in /sw/arch/RHEL8/EB_production/2023/software/SciPy-bundle/2023.07-gfbf-2023a/lib/python3.11/site-packages (from seaborn) (1.25.1)\n",
      "Requirement already satisfied: pandas>=1.2 in /sw/arch/RHEL8/EB_production/2023/software/SciPy-bundle/2023.07-gfbf-2023a/lib/python3.11/site-packages (from seaborn) (2.0.3)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in /sw/arch/RHEL8/EB_production/2023/software/matplotlib/3.7.2-gfbf-2023a/lib/python3.11/site-packages (from seaborn) (3.7.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /sw/arch/RHEL8/EB_production/2023/software/matplotlib/3.7.2-gfbf-2023a/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.1.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /sw/arch/RHEL8/EB_production/2023/software/matplotlib/3.7.2-gfbf-2023a/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /sw/arch/RHEL8/EB_production/2023/software/matplotlib/3.7.2-gfbf-2023a/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.42.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /sw/arch/RHEL8/EB_production/2023/software/matplotlib/3.7.2-gfbf-2023a/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /sw/arch/RHEL8/EB_production/2023/software/Python-bundle-PyPI/2023.06-GCCcore-12.3.0/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (23.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /sw/arch/RHEL8/EB_production/2023/software/Pillow/10.0.0-GCCcore-12.3.0/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (10.0.0)\n",
      "Requirement already satisfied: pyparsing<=3.1,>=2.3.1 in /sw/arch/RHEL8/EB_production/2023/software/Python-bundle-PyPI/2023.06-GCCcore-12.3.0/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.1.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /sw/arch/RHEL8/EB_production/2023/software/Python-bundle-PyPI/2023.06-GCCcore-12.3.0/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /sw/arch/RHEL8/EB_production/2023/software/Python-bundle-PyPI/2023.06-GCCcore-12.3.0/lib/python3.11/site-packages (from pandas>=1.2->seaborn) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /sw/arch/RHEL8/EB_production/2023/software/SciPy-bundle/2023.07-gfbf-2023a/lib/python3.11/site-packages (from pandas>=1.2->seaborn) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in /sw/arch/RHEL8/EB_production/2023/software/Python-bundle-PyPI/2023.06-GCCcore-12.3.0/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.16.0)\n",
      "Installing collected packages: seaborn\n",
      "Successfully installed seaborn-0.13.2\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "5230f6fe-e65d-47ed-b32b-a6007b054a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "results1 = [\n",
    "    (0.1, 0.006681514476614676, 0.0200445434298441),\n",
    "    (0.2, 0.00655021833976097, 0.013363028953229397),\n",
    "    (0.3, 0.004454342984574699, 0.011135857461024499),\n",
    "    (0.4, 0.004454342984409785, 0.013363028953229397),\n",
    "    (0.5, 0.006681514476688931, 0.011135857461024499),\n",
    "    (0.6, 0.006681514476614663, 0.013363028953229397),\n",
    "    (0.7, 0.006681514476859302, 0.015590200445434297),\n",
    "    (0.8, 0.008908685968819875, 0.024498886414253896),\n",
    "    (0.9, 0.01091703056791552, 0.028953229398663696)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "2ec1785b-48eb-4768-91eb-9f6050587584",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.set(style=\"whitegrid\")\n",
    "results = [(alpha, EER * 10, minDCF) for alpha, EER, minDCF in results]\n",
    "alpha, EER, minDCF = zip(*results)\n",
    "\n",
    "# Plotting EER vs alpha\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.lineplot(x=alpha, y=EER, marker='o', color='b')\n",
    "plt.title('ResNet WSE EER for different values of alpha on UCLA validation')\n",
    "plt.xlabel('Alpha')\n",
    "plt.ylabel('EER (%)')\n",
    "plt.savefig('EER.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "ad13ad33-40ad-4b3e-b222-29e4388626ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "sns.lineplot(x=alpha, y=minDCF, marker='o', color='b')\n",
    "plt.title('ResNet WSE minDCF for different values of alpha on UCLA validation')\n",
    "plt.xlabel('Alpha')\n",
    "plt.ylabel('MinDCF')\n",
    "plt.savefig('minDCF.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "8031814b-3015-43fb-945c-3759ac8a2f28",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ivbeveren/.local/lib/python3.11/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results at alpha = 0.1: 0.053872053870595626, 0.31200897867564487\n",
      "Results at alpha = 0.2: 0.052749719416385794, 0.25252525252525204\n",
      "Results at alpha = 0.3: 0.051627384961151476, 0.2289562289562285\n",
      "Results at alpha = 0.4: 0.0516273849607206, 0.22671156004489285\n",
      "Results at alpha = 0.5: 0.04826038159371492, 0.22671156004489285\n",
      "Results at alpha = 0.6: 0.04713804713762575, 0.22671156004489285\n",
      "Results at alpha = 0.7: 0.043771043772440565, 0.23232323232323182\n",
      "Results at alpha = 0.8: 0.04489337822665825, 0.2334455667788996\n",
      "Results at alpha = 0.9: 0.044893378226711585, 0.24915824915824863\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "alphas = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "for alpha in alphas:\n",
    "    interpolated_model = interpolate_models(pretrained_model, finetuned_model, alpha)\n",
    "    eer, mindcf = predict(interpolated_model)\n",
    "    results.append((alpha, eer, mindcf))\n",
    "    print(\"Results at alpha = \" + str(alpha) + \": \" + str(eer) + \", \" + str(mindcf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "0c757cd3-1df1-456b-868b-972f9f586af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "results1 = [\n",
    "    (0.1, 0.006681514476614676, 0.0200445434298441),\n",
    "    (0.2, 0.00655021833976097, 0.013363028953229397),\n",
    "    (0.3, 0.004454342984574699, 0.011135857461024499),\n",
    "    (0.4, 0.004454342984409785, 0.013363028953229397),\n",
    "    (0.5, 0.006681514476688931, 0.011135857461024499),\n",
    "    (0.6, 0.006681514476614663, 0.013363028953229397),\n",
    "    (0.7, 0.006681514476859302, 0.015590200445434297),\n",
    "    (0.8, 0.008908685968819875, 0.024498886414253896),\n",
    "    (0.9, 0.01091703056791552, 0.028953229398663696)\n",
    "]\n",
    "\n",
    "# New data\n",
    "results2 = [\n",
    "    (0.1, 0.053872053870595626, 0.31200897867564487),\n",
    "    (0.2, 0.052749719416385794, 0.25252525252525204),\n",
    "    (0.3, 0.051627384961151476, 0.2289562289562285),\n",
    "    (0.4, 0.0516273849607206, 0.22671156004489285),\n",
    "    (0.5, 0.04826038159371492, 0.22671156004489285),\n",
    "    (0.6, 0.04713804713762575, 0.22671156004489285),\n",
    "    (0.7, 0.043771043772440565, 0.23232323232323182),\n",
    "    (0.8, 0.04489337822665825, 0.2334455667788996),\n",
    "    (0.9, 0.044893378226711585, 0.24915824915824863)\n",
    "]\n",
    "\n",
    "# Multiply all EER values by 100\n",
    "results1 = [(alpha, EER * 100, minDCF) for alpha, EER, minDCF in results1]\n",
    "results2 = [(alpha, EER * 100, minDCF) for alpha, EER, minDCF in results2]\n",
    "\n",
    "# Unpacking the updated results into separate lists\n",
    "alpha1, EER1, minDCF1 = zip(*results1)\n",
    "alpha2, EER2, minDCF2 = zip(*results2)\n",
    "\n",
    "# Set the style of seaborn\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "# Plotting EER vs alpha\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.lineplot(x=alpha1, y=EER1, marker='o', color='b', label='UCLA')\n",
    "sns.lineplot(x=alpha2, y=EER2, marker='o', color='g', label='Commonvoice')\n",
    "plt.title('ResNet WSE EER for different values of alpha on UCLA and Commonvoice')\n",
    "plt.xlabel('Alpha')\n",
    "plt.ylabel('EER')\n",
    "plt.legend()\n",
    "plt.savefig('EER2.png')\n",
    "\n",
    "# Plotting minDCF vs alpha\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.lineplot(x=alpha1, y=minDCF1, marker='o', color='b', label='UCLA')\n",
    "sns.lineplot(x=alpha2, y=minDCF2, marker='o', color='g', label='Commonvoice')\n",
    "plt.title('ResNet WSE minDCF for different values of alpha on UCLA and Commonvoice')\n",
    "plt.xlabel('Alpha')\n",
    "plt.ylabel('minDCF')\n",
    "plt.legend()\n",
    "plt.savefig('minDCF2.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b592e485-94d5-43d9-8437-afb1c1215227",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
